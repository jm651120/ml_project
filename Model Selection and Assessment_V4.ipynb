{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_V4.csv',sep=',')\n",
    "X_val = pd.read_csv('X_val_V4.csv',sep=',')\n",
    "y_train = pd.read_csv('y_train_V4.csv',sep=',')\n",
    "y_val = pd.read_csv('y_val_V4.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating smaller stratified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, _, y_train_sample, _ = train_test_split(\n",
    "    X_train, y_train, test_size=0.6, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "X_val_sample, _, y_val_sample, _ = train_test_split(\n",
    "    X_val, y_val, test_size=0.6, random_state=42, stratify=y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the model and the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) #stratified kfold because data is imbalanced\n",
    "\n",
    "# # Define the XGBoost model with tuned parameters\n",
    "# model = XGBClassifier(\n",
    "#     n_estimators=200,         # Increase the number of trees to capture more patterns\n",
    "#     max_depth=6,              # Moderate depth to control complexity\n",
    "#     learning_rate=0.1,        # Adjusted learning rate for optimization\n",
    "#     scale_pos_weight=1,       # Initial adjustment for imbalance (optimize further if needed)\n",
    "#     random_state=42,\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='mlogloss'\n",
    "# )\n",
    "\n",
    "# # Adding SMOTE and UNDERSAMPLE to deal with class imbalance\n",
    "# pipeline = Pipeline([\n",
    "#     ('smote', SMOTE(sampling_strategy='not majority', random_state=42)),\n",
    "#     ('undersample', RandomUnderSampler(sampling_strategy='auto', random_state=42)),\n",
    "#     ('classifier', model)\n",
    "# ])\n",
    "\n",
    "\n",
    "# #0.68 on training\n",
    "# #0.45 on val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratified K-Fold for cross-validation due to class imbalance\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the XGBoost model with tuned parameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,         \n",
    "    max_depth=6,              \n",
    "    learning_rate=0.1,        \n",
    "    scale_pos_weight=1,       \n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'    \n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Average Macro F1-Score on training folds: 0.6863\n",
    "# Average Macro F1-Score on validation folds: 0.4185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Stratified K-Fold devido ao desbalanceamento\n",
    "\n",
    "# # Definição do modelo Random Forest\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=200,          # Número de árvores na floresta\n",
    "#     max_depth=10,              # Profundidade máxima de cada árvore\n",
    "#     min_samples_split=5,       # Mínimo de amostras necessárias para dividir um nó\n",
    "#     min_samples_leaf=2,        # Mínimo de amostras necessárias em um nó folha\n",
    "#     class_weight='balanced',   # Ajusta pesos para o desbalanceamento\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Average Macro F1-Score on training folds: 0.4244\n",
    "# # Average Macro F1-Score on validation folds: 0.3889\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) \n",
    "\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # Average Macro F1-Score on training folds: \n",
    "# # Average Macro F1-Score on validation folds: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Cross Validation on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:57:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\rodri\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:57:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\rodri\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:57:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\rodri\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:58:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\rodri\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:58:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Macro F1-Score on training folds: 0.6863\n",
      "Average Macro F1-Score on validation folds: 0.4185\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "val_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_sample, y_train_sample):\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_fold_train, X_fold_val = X_train_sample.iloc[train_index], X_train_sample.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_sample.iloc[train_index], y_train_sample.iloc[val_index]\n",
    "    \n",
    "    # Fit the pipeline on the training fold\n",
    "    pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Predict and score on the training fold\n",
    "    y_train_pred = pipeline.predict(X_fold_train)\n",
    "    train_f1 = f1_score(y_fold_train, y_train_pred, average='macro')\n",
    "    train_scores.append(train_f1)\n",
    "    \n",
    "    # Predict and score on the validation fold\n",
    "    y_val_pred = pipeline.predict(X_fold_val)\n",
    "    val_f1 = f1_score(y_fold_val, y_val_pred, average='macro')\n",
    "    val_scores.append(val_f1)\n",
    "\n",
    "# Calculate and print average F1-macro scores for both training and validation\n",
    "print(f\"Average Macro F1-Score on training folds: {np.mean(train_scores):.4f}\")\n",
    "print(f\"Average Macro F1-Score on validation folds: {np.mean(val_scores):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ocurring in overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the model to the full dataset after we get a good F1 Macro score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_val_pred_full = pipeline.predict(X_val)\n",
    "final_score_full = f1_score(y_val, y_val_pred_full, average='macro')\n",
    "print(f\"Macro F1-Score on final validation set (full dataset): {final_score_full:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
