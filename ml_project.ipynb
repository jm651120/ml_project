{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, options and ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the training and test data\n",
    "df = pd.read_csv('/home/shadybea/OneDrive/General/Machine Learning/Project/Data/train_data.csv', sep=',')\n",
    "df_test = pd.read_csv('/home/shadybea/OneDrive/General/Machine Learning/Project/Data/test_data.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by importing the dataset, we get a warning saying column 29 has mixed data types - we will check this in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Macro-inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the first rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check if there are any aggregation rows at the end of the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the datatypes and null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data type analysis:**\n",
    "\n",
    "Features that should be integers:\n",
    "- 'Age at Injury'\n",
    "- 'Birth Year'\n",
    "- 'IME-4 Count'\n",
    "- 'Industry Code'\n",
    "- 'WCIO Cause of Injury Code'\n",
    "- 'WCIO Nature of Injury Code'\n",
    "- 'WCIO Part Of Body Code'\n",
    "- 'Number of Dependents'\n",
    "\n",
    "Features that should be booleans:\n",
    "- 'Agreement Reached'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Claim Identifier\n",
    "\n",
    "This feature is the unique identifier of each claim - we will analyse this column in more depth in an attempt to assign it as the index of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check if there are any duplicate values for this column\n",
    "df[df['Claim Identifier'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, we have one duplicated 'Claim Identifier', where all values, except for 'Assembly Date', are NaNs. </br>\n",
    "We will use the default python behavior and drop the second appearence of the repeated 'Claim Identifier'. </br>\n",
    "As we saw previously, this column has no null values, so we can set it as the dataframe index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Claim Identifier'].duplicated()].set_index('Claim Identifier').rename_axis(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaNs for each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# Get the total number of rows (entries) in the DataFrame\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# Calculate the percentage of NaN values for each column\n",
    "percentage_nans = (nan_counts / total_rows) * 100\n",
    "\n",
    "# Format the percentage with '%' sign\n",
    "percentage_nans = percentage_nans.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Combine all information into a DataFrame for better readability\n",
    "nan_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Total Values': [total_rows] * len(nan_counts),  # Ensure this column matches the length of nan_counts\n",
    "    'Percentage NaN': percentage_nans\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(\"Summary of NaN values per column:\\n\")\n",
    "print(nan_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing the output above, we conclude:\n",
    "- **'C-3 Date'**: more than 50% of the data for this feature is missing, it can be due to process status - the employee has not yet sent its report\n",
    "- **'First Hearing Date'**: around 75% of the data for this feature is missing - this means hearings have not yet been scheduled\n",
    "- **'IME-4 Count'**: more than 75% of the data for this feature is missing, it can be due to process status - the independent examiner has not yet sent its report\n",
    "- **'OIICS Nature of Injury Description'**: only has null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.1. Accident Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few missing values for 'Accident Date'; however, these values can be imputed if we have information about 'Age at Injury' and 'Birth Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accident Date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Accident Date'].isna()) & ~((df['Age at Injury'].isna()) | (df['Age at Injury'] == 0.0)) & ~(df['Birth Year'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no way of deducing missing values for 'Accident Date'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.2. Age at Injury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few missing values for 'Age at Injury'; however, these values can be imputed if we have information about 'Accident Date' and 'Birth Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age at Injury'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Age at Injury'].isna()) & ~((df['Accident Date'].isna())) & ~(df['Birth Year'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no way of deducing missing values for 'Age at Injury'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.3. Birth Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few missing values for 'Birth Year'; however, these values can be imputed if we have information about 'Accident Date' and 'Age at Injury'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Birth Year'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Birth Year'].isna()) & ~((df['Accident Date'].isna())) & ~(df['Age at Injury'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be able to deduce a good amount of values for 'Birth Year'. </br>\n",
    "We do this in section TK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Data types\n",
    "\n",
    "As we imported the data, we got a warning saying columns had mixed data types. We shall take a look at this issue now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mixed_types(column):\n",
    "    return len(set(column[pd.notna(column)].apply(type))) > 1  # If there are more than one unique data types, excluding NaN values (as these are considered as floats)\n",
    "\n",
    "# Apply the function to all columns and filter out the mixed-type columns\n",
    "mixed_type_columns = [col for col in df.columns if check_mixed_types(df[col])]\n",
    "\n",
    "print(mixed_type_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mixed_type_columns:\n",
    "    print(df[col].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for 'Zip Code' are split across two data types - string and float. We shall look at the feature values in order to make a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check if there are any values that contain any non numeric character\n",
    "print(df[df['Zip Code'].apply(lambda x: bool(re.search(r'\\D', str(x))))]['Zip Code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have determined that there are values for 'Zip Code' that contain other than numeric characters, we shall set this feature as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of the values to string\n",
    "df['Zip Code'] = df['Zip Code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-checking the data type counts\n",
    "print(df['Zip Code'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fixed the remaining data types, as identified in [Section 2.1](#21-macro-inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dictionary that stores the column names\n",
    "type_cast = {\n",
    "    'int_features': ['Age at Injury', 'Birth Year', 'IME-4 Count', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Number of Dependents']\n",
    "    , 'bool_features': ['Agreement Reached']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datatype(df, type_cast):\n",
    "    for dtype, columns in type_cast.items():        \n",
    "        if dtype == 'int_features':\n",
    "            # Apply numeric conversion\n",
    "            for col in columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "                \n",
    "        elif dtype == 'bool_features':\n",
    "            # Apply boolean conversion\n",
    "            for col in columns:\n",
    "                df[col] = df[col].apply(lambda x: x if pd.isna(x) else bool(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_datatype(df, type_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the conversion was successful\n",
    "for subset in type_cast:\n",
    "    for col in type_cast[subset]:\n",
    "        print(col, '\\t', df[col].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the number of unique values for each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the unique values for each column\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'feature_type': [df[column].dtype for column in df.columns],\n",
    "        'unique_values': df.apply(lambda col: sorted(pd.Series(col.dropna().unique().tolist())))  # we disregard NaN values, so we can sort the unique values\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this information, we can point out the following:\n",
    "- **Age at Injury**: since this dataset concerns workplace injuries, values under 14 (legal working age in the US) are weird\n",
    "- **Birth Year**: we have '0.0' values\n",
    "- **Gender**: this is not a binary feature\n",
    "- **OIICS Nature of Injury Description**: has no values\n",
    "- **WCIO Part Of Body Code**: has a negative value\n",
    "- **WCB Decision**: only has one value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Date formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['Accident Date', 'Assembly Date', 'C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "\n",
    "# regex pattern for the format YYYY-MM-DD\n",
    "date_pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "\n",
    "# check if there are any values in these date columns that do not follow this format\n",
    "for column in date_columns:\n",
    "    display(df[df[column].apply(lambda x: pd.notna(x) and not bool(re.match(date_pattern, str(x))))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6. Inconsistencies\n",
    "\n",
    "##### 2.3.6.1. Codes vs. Descriptions\n",
    "\n",
    "In this section, we will check if the amount of codes are the same as the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Industry Code'].dropna().unique()) == len(df['Industry Code Description'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Industry Code', 'Industry Code Description']).size().reset_index(name='count').sort_values('Industry Code Description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"repeated\" values of 'Industry Code Description' occur for consecutive 'Industry Code' values - one could consider replacing the different values for 'Industry Code' for a unique one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['WCIO Cause of Injury Code'].dropna().unique()) == len(df['WCIO Cause of Injury Description'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['WCIO Cause of Injury Code', 'WCIO Cause of Injury Description']).size().reset_index(name='count').sort_values(by='WCIO Cause of Injury Description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, one could aggregate the same value for the description in the same code. There is also some values that are rather similiar that could be aggregated (e.g. 'MOVING PART OF MACHINE' and 'MOVING PARTS OF MACHINE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['WCIO Nature of Injury Code'].dropna().unique()) == len(df['WCIO Nature of Injury Description'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['WCIO Part Of Body Code'].dropna().unique()) == len(df['WCIO Part Of Body Description'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['WCIO Part Of Body Code', 'WCIO Part Of Body Description']).size().reset_index(name='count').sort_values(by='WCIO Part Of Body Description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we have descriptions associated to multiple codes - we can aggregate these descriptions into one single code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.2. The wanna-be NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check if there are NaN values that are coded as string values, instead of the default np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check if any column contains the string 'nan'\n",
    "contains_nan_string = df.apply(lambda col: col.isin(['nan']).any())\n",
    "\n",
    "# we get the columns that contain 'nan'\n",
    "columns_with_nan_string = contains_nan_string[contains_nan_string].index.tolist()\n",
    "\n",
    "columns_with_nan_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed we have string representations of missing values in 'Zip Code' - we shall convert these into actual NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip Code'] = df['Zip Code'].replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.3. Duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check how many duplicated rows we have\n",
    "df.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check how many of these are distinct\n",
    "len(df[df.duplicated(keep=False)].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, even though we have 19k+ duplicated rows, 1k of these rows are distinct, i.e., we have rows with more than one duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall check if all values of all rows are NaN with the exception of 'Assembly Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop duplicates from those duplicated rows\n",
    "unique_duplicated_rows = df[df.duplicated(keep=False)].drop_duplicates()\n",
    "\n",
    "# we check if all values (excluding 'Assembly Date') are NaN\n",
    "nan_check = unique_duplicated_rows.drop(columns='Assembly Date').isna().all(axis=1)\n",
    "\n",
    "# we check the rows that have other than missing values\n",
    "unique_duplicated_rows[~nan_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that all duplicated rows have missing values in every column but 'Assembly Date', except for one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of duplicate values\n",
    "df.duplicated().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated (and \"empty\") rows we have been discussing account for around 3.1% of our data - we will drop these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.4. The target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check how many missing values we have in our target variable\n",
    "df['Claim Injury Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Claim Injury Type'].isna()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a first glance, it looks like these rows are all NaN values with the exception of 'Assembly Date' - just like before. Let us check if this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_target_df = df[df['Claim Injury Type'].isna()]\n",
    "\n",
    "# we check if all values (excluding 'Assembly Date') are NaN\n",
    "nan_check = no_target_df.drop(columns='Assembly Date').isna().all(axis=1)\n",
    "\n",
    "# we check the rows that have other than missing values\n",
    "no_target_df[~nan_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like all these rows have missing values in every column but 'Assembly Date' - we will also remove these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Claim Injury Type'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the original dataset had 593471 rows, let us check what percentage of the data we have removed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - (df.shape[0] / 593471)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still below the 5% threshold rule of thumb, so we are good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Statistical pitstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recheck our count of missing values once more and look at some statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Missing values (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaNs for each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# Get the total number of rows (entries) in the DataFrame\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# Calculate the percentage of NaN values for each column\n",
    "percentage_nans = (nan_counts / total_rows) * 100\n",
    "\n",
    "# Format the percentage with '%' sign\n",
    "percentage_nans = percentage_nans.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Combine all information into a DataFrame for better readability\n",
    "nan_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Total Values': [total_rows] * len(nan_counts),  # Ensure this column matches the length of nan_counts\n",
    "    'Percentage NaN': percentage_nans\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(\"Summary of NaN values per column:\\n\")\n",
    "print(nan_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have considerably reduced the number of missing values - nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now start the visual inspection of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by defining our numeric and categorical features\n",
    "numeric_features = df[['Age at Injury', 'Average Weekly Wage', 'IME-4 Count']].columns.tolist()\n",
    "categorical_features = df[['Accident Date', 'Alternative Dispute Resolution', 'Assembly Date', 'Attorney/Representative', \n",
    "       'Birth Year', 'C-2 Date', 'C-3 Date', 'Carrier Type', 'Claim Injury Type', 'County of Injury', 'COVID-19 Indicator',\n",
    "       'District Name', 'First Hearing Date', 'Gender', 'Industry Code', 'Medical Fee Region', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code', 'Agreement Reached', 'WCB Decision', \n",
    "       'Number of Dependents']].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(numeric_features)\n",
    "num_columns = 2\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms\n",
    "for ax, feature in zip(axes, numeric_features):\n",
    "    ax.hist(df[feature].dropna(), bins=30, color='skyblue', alpha=0.7)  # alpha for transparency\n",
    "    ax.set_title(f'Histogram of {feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(numeric_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the subplots with 4 columns\n",
    "num_features = len(categorical_features)\n",
    "num_columns = 4\n",
    "num_rows = (num_features + num_columns - 1) // num_columns  # Calculate the required number of rows\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each categorical feature to plot bar plots\n",
    "for ax, feature in zip(axes, categorical_features):\n",
    "    value_counts = df[feature].value_counts()\n",
    "    value_counts.plot(kind='bar', ax=ax, color='skyblue', alpha=0.7)  # Bar plot\n",
    "    ax.set_title(f'Bar Plot of {feature}')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(axis='y')  # Only show gridlines for y-axis\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(categorical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2024.10.24 12:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age at Injury'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove 19445 rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 19445 rows with NaN values\n",
    "df_nulos = df[df['Age at Injury'].isnull()]\n",
    "df = df.drop(df_nulos.index)\n",
    "df = df.drop('OIICS Nature of Injury Description', axis=1)\n",
    "\n",
    "# Calculate the number of NaNs for each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# Get the total number of rows (entries) in the DataFrame\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# Calculate the percentage of NaN values for each column\n",
    "percentage_nans = (nan_counts / total_rows) * 100\n",
    "\n",
    "# Format the percentage with '%' sign\n",
    "percentage_nans = percentage_nans.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Combine all information into a DataFrame for better readability\n",
    "nan_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'Total Values': [total_rows] * len(nan_counts),  # Ensure this column matches the length of nan_counts\n",
    "    'Percentage NaN': percentage_nans\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(\"Summary of NaN values per column:\")\n",
    "print(nan_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(12, 30), tight_layout=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(df_numeric):\n",
    "    sns.histplot(x=df_numeric[column], bins=20, ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram de {column}')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age at Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['Age at Injury'].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Dispute Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Alternative Dispute Resolution'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature: Days Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter as colunas para o formato de data, se ainda não estiverem\n",
    "df['Accident Date'] = pd.to_datetime(df['Accident Date'])\n",
    "df['Assembly Date'] = pd.to_datetime(df['Assembly Date'])\n",
    "\n",
    "# Calcular a diferença de dias entre as duas colunas\n",
    "df['Days Difference'] = (df['Assembly Date'] - df['Accident Date']).dt.days\n",
    "\n",
    "# DataFrame com a nova coluna\n",
    "print(df[['Accident Date', 'Assembly Date', 'Days Difference']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attorney/Representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attorney/Representative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'Attorney/Representative' is a non-numeric column\n",
    "plt.figure(figsize=(12, 6))  # Setup figure size\n",
    "\n",
    "# Create a count plot for 'Attorney/Representative'\n",
    "sns.countplot(x=df['Attorney/Representative'])\n",
    "plt.title('Count of Attorney/Representative')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Average Weekly Wage']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'Average Weekly Wage' is a numeric column\n",
    "plt.figure(figsize=(12, 6))  # Setup figure size\n",
    "\n",
    "# Create a boxplot for 'Average Weekly Wage'\n",
    "sns.boxplot(x=df['Average Weekly Wage'])\n",
    "plt.title('Boxplot of Average Weekly Wage')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'Average Weekly Wage' is the column of interest\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create a histogram for the 'Average Weekly Wage'\n",
    "sns.histplot(df['Average Weekly Wage'].dropna(), bins=20, kde=False, color='blue')\n",
    "plt.title('Histogram of Average Weekly Wage')\n",
    "plt.xlabel('Average Weekly Wage')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate value counts including NaN\n",
    "value_counts = df['Average Weekly Wage'].value_counts(dropna=False)\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = df['Average Weekly Wage'].size\n",
    "\n",
    "# Calculate the percentage of 0.0 values\n",
    "percent_zero = (value_counts.get(0.0, 0) / total_entries) * 100\n",
    "\n",
    "# Calculate the percentage of NaN values using np.isnan and sum\n",
    "percent_nan = (df['Average Weekly Wage'].isna().sum() / total_entries) * 100\n",
    "\n",
    "# Calculate the percentage of all other values\n",
    "percent_others = 100 - (percent_zero + percent_nan)\n",
    "\n",
    "# Print the results\n",
    "print('Average Weekly Wage Percentages:')\n",
    "print(f\"0.0 values: {percent_zero:.2f}%\")\n",
    "print(f\"NaN values: {percent_nan:.2f}%\")\n",
    "print(f\"All other values: {percent_others:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Average Weekly Wage']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Birth Year']==0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.stripplot(x=df['Birth Year'], jitter=0.1, size=5, color='purple', alpha=0.6)\n",
    "plt.title('Distribution of Birth Years')\n",
    "plt.xlabel('Birth Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['Carrier Name'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(20).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Top 20 Carrier Names by Frequency')\n",
    "plt.xlabel('Carrier Name')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Carrier Name'] == 'STATE INSURANCE FUND').value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim Injury Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['Claim Injury Type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(20).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Claim Injury Type Count')\n",
    "plt.xlabel('Claim Injury Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County of Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['County of Injury'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(30).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Top 30 County of Injury')\n",
    "plt.xlabel('County of Injury')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['COVID-19 Indicator'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(20).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('COVID-19 Indicator by Frequency')\n",
    "plt.xlabel('COVID-19 Indicator')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['District Name'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(20).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('District Name by Frequency')\n",
    "plt.xlabel('District Name')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values= df['District Name'].dropna().value_counts()\n",
    "\n",
    "plt.pie(values, labels=values.index.astype(str), autopct='%1.1f%%')\n",
    "plt.title('Distribution of District Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['Gender'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(20).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Gender by Frequency')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IME-4 Count Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'carrier_counts' contains the value counts of the 'IME-4 Count' column\n",
    "top_10 = carrier_counts.head(10)\n",
    "other = carrier_counts.iloc[10:].sum()  # Sum the counts beyond the top 10\n",
    "\n",
    "# Create a new series that includes 'Other' using pd.concat\n",
    "pie_data = pd.concat([top_10, pd.Series([other], index=['Other'])])\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "pie_data.plot(kind='pie', autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0','#ffb3e6', '#c4e17f', '#76d7c4', '#f7c6c7', '#f7b7a3', '#d4e157'])\n",
    "plt.title('IME-4 Count Distribution including Other')\n",
    "plt.ylabel('')  # Pie chart does not require a y-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['Industry Code'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 8))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(24).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Industry Code by Frequency')\n",
    "plt.xlabel('Industry Code')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Industry Code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry Code Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = df['Industry Code Description'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 10))  # Adjust the figure size as necessary\n",
    "carrier_counts.head(24).plot(kind='bar', color='skyblue')  # Show top 20 carriers for readability\n",
    "plt.title('Industry Code Description by Frequency')\n",
    "plt.xlabel('Industry Code Description')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines for better visual comparison\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each number of dependents\n",
    "dependent_counts = df['Number of Dependents'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.pointplot(x=dependent_counts.index, y=dependent_counts.values)\n",
    "plt.title('Dot Plot of Number of Dependents')\n",
    "plt.xlabel('Number of Dependents')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values and count occurrences of each number of dependents\n",
    "value_counts = df['Number of Dependents'].dropna().value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(value_counts, labels=value_counts.index.astype(str), autopct='%1.1f%%')\n",
    "plt.title('Distribution of Number of Dependents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCIO Nature of Injury Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para remover valores nulos na coluna de lesões\n",
    "filtered_data = df.dropna(subset=['WCIO Nature of Injury Description'])\n",
    "\n",
    "# Contar as 5 lesões mais comuns\n",
    "top_injuries = filtered_data['WCIO Nature of Injury Description'].value_counts().head(5)\n",
    "\n",
    "# Exibir as 5 lesões mais comuns\n",
    "print(top_injuries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valores de 'SPRAIN OR TEAR' por 'STRAIN OR TEAR' (ou vice-versa, dependendo da sua escolha)\n",
    "filtered_data['WCIO Nature of Injury Description'] = filtered_data['WCIO Nature of Injury Description'].replace('SPRAIN OR TEAR', 'STRAIN OR TEAR')\n",
    "\n",
    "# Contar novamente as 5 lesões mais comuns após a unificação\n",
    "top_injuries_unified = filtered_data['WCIO Nature of Injury Description'].value_counts().head(5)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(top_injuries_unified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between WCIO Nature of Injury Description and Industry Code Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as 5 lesões mais comuns após a unificação\n",
    "common_injuries = ['STRAIN OR TEAR']\n",
    "\n",
    "# Filtrar o dataset para conter apenas essas lesões\n",
    "filtered_data = filtered_data[filtered_data['WCIO Nature of Injury Description'].isin(common_injuries)]\n",
    "\n",
    "# Gráfico de barras para visualizar a relação entre lesões e tipo de trabalho\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='Industry Code Description', hue='WCIO Nature of Injury Description', data=filtered_data)\n",
    "plt.title('Relation between WCIO Nature of Injury Description and Industry Code Description')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Tipo de Lesão', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Gráfico de boxplot para analisar a idade dos trabalhadores por tipo de lesão\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='WCIO Nature of Injury Description', y='Age at Injury', data=filtered_data)\n",
    "plt.title('Relation between WCIO Nature of Injury Description and Industry Code Description')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Alternative Dispute Resolution']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Attorney/Representative and Claim Injury Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados onde 'Alternative Dispute Resolution' é 'Y'\n",
    "adr_yes = df[df['Alternative Dispute Resolution'] == 'Y']\n",
    "\n",
    "# Contar os valores únicos de 'Claim Injury Type' para os casos com ADR 'Y'\n",
    "claim_injury_type_counts_adr_yes = adr_yes['Claim Injury Type'].value_counts()\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"Claim Injury Type when 'Alternative Dispute Resolution' == 'Y'\")\n",
    "print(claim_injury_type_counts_adr_yes)\n",
    "\n",
    "# Calcular a percentagem de cada 'Claim Injury Type' quando 'Alternative Dispute Resolution' é 'Y'\n",
    "claim_injury_type_percentage_adr_yes = (claim_injury_type_counts_adr_yes / claim_injury_type_counts_adr_yes.sum()) * 100\n",
    "\n",
    "# Exibir as percentagens\n",
    "print(claim_injury_type_percentage_adr_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar gráfico para visualizar a relação entre 'Alternative Dispute Resolution' e 'Claim Injury Type'\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Attorney/Representative', hue='Claim Injury Type', data=df)\n",
    "plt.title('Relation between Attorney/Representative and Claim Injury Type')\n",
    "plt.xlabel('Attorney/Representative')\n",
    "plt.ylabel('Contagem')\n",
    "plt.legend(title='Attorney/Representative', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma tabela cruzada (crosstab) para contar a frequência de 'Claim Injury Type' em função de 'Attorney/Representative'\n",
    "claim_injury_type_by_attorney = pd.crosstab(df['Claim Injury Type'], df['Attorney/Representative'])\n",
    "\n",
    "# Calcular a percentagem de cada valor no total para advogado e não advogado\n",
    "claim_injury_type_percentage = claim_injury_type_by_attorney.apply(lambda x: x / x.sum() * 100, axis=1)\n",
    "\n",
    "# Concatenar os valores absolutos com as percentagens\n",
    "claim_injury_type_with_percentage = pd.concat([claim_injury_type_by_attorney, claim_injury_type_percentage], axis=1, keys=['Count', 'Percentage'])\n",
    "\n",
    "# Exibir o resultado\n",
    "print(claim_injury_type_with_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Wage by Attorney/Representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Calculate the mean 'Average Weekly Wage' for each 'Attorney/Representative' category\n",
    "mean_wage_by_lawyer = df.groupby('Attorney/Representative')['Average Weekly Wage'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_plot = sns.barplot(x='Attorney/Representative', y='Average Weekly Wage', data=mean_wage_by_lawyer)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Average Weekly Wage by Attorney/Representative')\n",
    "plt.xlabel('Attorney/Representative (Y/N)')\n",
    "plt.ylabel('Average Weekly Wage')\n",
    "\n",
    "# Annotate the bar plot with the actual mean values\n",
    "for index, row in mean_wage_by_lawyer.iterrows():\n",
    "    bar_plot.text(index, row['Average Weekly Wage'], f\"{row['Average Weekly Wage']:.2f}\", \n",
    "                  color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Carrier Type and Claim Injury Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Carrier Type', hue='Claim Injury Type', data=df)\n",
    "plt.title('Relation between Carrier Type and Claim Injury Type')\n",
    "plt.xlabel('Carrier Type')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Claim Injury Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Carrier Type', hue='Attorney/Representative', data=df)\n",
    "plt.title('Relation between Carrier Type and Claim Injury Type')\n",
    "plt.xlabel('Carrier Type')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Attorney/Representative', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma tabela cruzada (crosstab) para contar a frequência de 'Carrier Type' em função de 'Attorney/Representative'\n",
    "carrier_type_with_attorney_counts = pd.crosstab(df['Carrier Type'], df['Attorney/Representative'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(carrier_type_with_attorney_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between COVID-19 Indicator and Claim Injury Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_yes = df[df['COVID-19 Indicator'] == 'Y']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='COVID-19 Indicator', hue='Claim Injury Type', data=covid_yes)\n",
    "plt.title('Relation between COVID-19 Indicator and Claim Injury Type')\n",
    "plt.xlabel('COVID-19 Indicator')\n",
    "plt.ylabel('Contagem')\n",
    "plt.legend(title='Claim Injury Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados onde 'COVID-19 Indicator' é 'Y'\n",
    "covid_yes = df[df['COVID-19 Indicator'] == 'Y']\n",
    "\n",
    "# Contar o número de ocorrências de 'Claim Injury Type' para os casos com 'COVID-19 Indicator' = 'Y'\n",
    "covid_yes_claim_injury_counts = covid_yes['Claim Injury Type'].value_counts()\n",
    "\n",
    "# Calcular a percentagem de cada tipo de lesão\n",
    "total_claims = covid_yes_claim_injury_counts.sum()\n",
    "covid_yes_claim_injury_percentage = (covid_yes_claim_injury_counts / total_claims) * 100\n",
    "\n",
    "# Calcular a percentagem acumulada\n",
    "covid_yes_claim_injury_cumulative_percentage = covid_yes_claim_injury_percentage.cumsum()\n",
    "\n",
    "# Criar um DataFrame com as contagens, percentagens e percentagem acumulada\n",
    "covid_yes_claim_injury_df = pd.DataFrame({\n",
    "    'Count': covid_yes_claim_injury_counts,\n",
    "    'Percentage': covid_yes_claim_injury_percentage,\n",
    "    'Cumulative Percentage': covid_yes_claim_injury_cumulative_percentage\n",
    "})\n",
    "\n",
    "# Exibir o resultado\n",
    "print(\"Claim Injury Type para casos onde COVID-19 Indicator = 'Y'\")\n",
    "print(covid_yes_claim_injury_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation betweenAge at Injury and Mean IME-4 Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot\n",
    "mean_ime_by_age = df.groupby('Age at Injury')['IME-4 Count'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='Age at Injury', y='IME-4 Count', data=mean_ime_by_age, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean IME-4 Count by Age at Injury')\n",
    "plt.xlabel('Age at Injury')\n",
    "plt.ylabel('Mean IME-4 Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Average Weekly Wage and Attorney/Representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'Average Weekly Wage' is 0.0 or NaN\n",
    "filtered_df = df[df['Average Weekly Wage'] > 0]\n",
    "\n",
    "# Ensure that the column names match exactly the ones in your dataset.\n",
    "# Group by 'Attorney/Representative' and calculate the mean 'Average Weekly Wage'\n",
    "mean_wage_by_lawyer = filtered_df.groupby('Attorney/Representative')['Average Weekly Wage'].mean().reset_index()\n",
    "\n",
    "print(mean_wage_by_lawyer)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Attorney/Representative', y='Average Weekly Wage', data=mean_wage_by_lawyer, palette='viridis')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Average Weekly Wage by Attorney/Representative')\n",
    "plt.xlabel('Attorney/Representative (Y/N)')\n",
    "plt.ylabel('Average Weekly Wage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Mean Average Weekly Wage and Age at Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot\n",
    "mean_wage_by_age = df.groupby('Age at Injury')['Average Weekly Wage'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='Age at Injury', y='Average Weekly Wage', data=mean_wage_by_age, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Average Weekly Wage by Age at Injury')\n",
    "plt.xlabel('Age at Injury')\n",
    "plt.ylabel('Average Weekly Wage')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Mean Days Difference and Age at Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot\n",
    "mean_daysdif_by_age = df.groupby('Age at Injury')['Days Difference'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='Age at Injury', y='Days Difference', data=mean_daysdif_by_age, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Days Difference by Age at Injury')\n",
    "plt.xlabel('Age at Injury')\n",
    "plt.ylabel('Days Difference')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Mean Days Difference and Average Weekly Wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot\n",
    "mean_daysdif_by_wage = df.groupby('Average Weekly Wage')['Days Difference'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='Average Weekly Wage', y='Days Difference', data=mean_daysdif_by_wage, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Days Difference by Average Weekly Wage')\n",
    "plt.xlabel('Average Weekly Wage')\n",
    "plt.ylabel('Days Difference')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Mean Days Difference and District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daysdif_by_district = df.groupby('District Name')['Days Difference'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_plot = sns.barplot(x='District Name', y='Days Difference', data=mean_daysdif_by_district)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Days Difference by District')\n",
    "plt.xlabel('District')\n",
    "plt.ylabel('Days Difference')\n",
    "\n",
    "# Annotate the bar plot with the actual mean values\n",
    "for index, row in mean_daysdif_by_district.iterrows():\n",
    "    bar_plot.text(index, row['Days Difference'], f\"{row['Days Difference']:.2f}\", \n",
    "                  color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion between Atorney/Representative within District Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(df['District Name'], df['Attorney/Representative'], normalize='index')\n",
    "\n",
    "# Plotar o gráfico de barras empilhadas com proporções\n",
    "cross_tab.plot(kind='bar', stacked=True, figsize=(8, 6), color=['skyblue', 'salmon'])\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.title('Proportion of Attorney/Representative within District Name')\n",
    "plt.xlabel('District Name')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Attorney/Representative', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Days Difference by Attorney/Representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daysdif_by_lawyer = df.groupby('Attorney/Representative')['Days Difference'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_plot = sns.barplot(x='Attorney/Representative', y='Days Difference', data=mean_daysdif_by_lawyer)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Days Difference by Attorney/Representative')\n",
    "plt.xlabel('Attorney/Representative (Y/N)')\n",
    "plt.ylabel('Days Difference')\n",
    "\n",
    "# Annotate the bar plot with the actual mean values\n",
    "for index, row in mean_daysdif_by_lawyer.iterrows():\n",
    "    bar_plot.text(index, row['Days Difference'], f\"{row['Days Difference']:.2f}\", \n",
    "                  color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
