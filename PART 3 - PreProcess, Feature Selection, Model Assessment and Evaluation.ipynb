{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS - PART 3: DATA PRE-PROCESSING, FEATURE SELECTION, MODEL ASSESSMENT AND EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<font color='steelblue'>1. - __Data Pre-Processing__</font>](#one-bullet) <br>\n",
    "    [<font color='steelblue'>1.1. - Imports and Initial Transformations</font>](#two-bullet) <br>\n",
    "    [<font color='steelblue'>1.2. - Data Cleaning</font>](#three-bullet) <br>\n",
    "    [<font color='steelblue'>1.3. - Missing Values</font>](#four-bullet) <br>\n",
    "    [<font color='steelblue'>1.4. - Simple Encoding</font>](#five-bullet) <br>\n",
    "    [<font color='steelblue'>1.5. - Pipeline Preparation</font>](#six-bullet) <br>\n",
    "\n",
    "[<font color='steelblue'>2. - __Feature Selection__</font>](#seven-bullet) <br>\n",
    "    [<font color='steelblue'>2.1. - Spearman Correlation</font>](#eight-bullet) <br>\n",
    "    [<font color='steelblue'>2.2. - XGBoost</font>](#nine-bullet) <br>\n",
    "    [<font color='steelblue'>2.3. - Decision Trees</font>](#ten-bullet) <br>\n",
    "\n",
    "[<font color='steelblue'>3. - __Model Assessment__</font>](#eleven-bullet) <br>\n",
    "    [<font color='steelblue'>3.1. - Pre Model</font>](#twelve-bullet) <br>\n",
    "    [<font color='steelblue'>3.2. - XGBoost</font>](#thirteen-bullet) <br>\n",
    "    [<font color='steelblue'>3.3. - Neural Network</font>](#fourteen-bullet) <br>\n",
    "    [<font color='steelblue'>3.4. - Decision Tree</font>](#fifteen-bullet) <br>\n",
    "    [<font color='steelblue'>3.5. - Logistic Regression</font>](#sixteen-bullet) <br>\n",
    "    [<font color='steelblue'>3.6. - Random Forest</font>](#seventeen-bullet) <br>\n",
    "    [<font color='steelblue'>3.7. - Naive Bayes</font>](#eighteen-bullet) <br>\n",
    "    [<font color='steelblue'>3.8. - Stacking: Logistic Regression and Naive Bayes</font>](#nineteen-bullet) <br>\n",
    "\n",
    "[<font color='steelblue'>4. - __Model Evaluation__</font>](#twenty-bullet) <br>\n",
    "    [<font color='steelblue'>4.1. - Accuracy Macro, Precision Macro, Recall Macro, F1 Macro</font>](#twentyone-bullet) <br>\n",
    "    [<font color='steelblue'>4.2. - Prediction Submission</font>](#twentytwo-bullet) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"one-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "## 1. Data Pre-Processing\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"two-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 1.1. Imports and Initial Transformations\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict, StratifiedKFold, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score, recall_score, precision_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'train': 'df',\n",
    "    'test': 'df_test'\n",
    "}\n",
    "\n",
    "for name, dataframe in df_dict.items():\n",
    "    # open the json with the dataframe datatypes\n",
    "    with open(f'{name}_dtypes_visual_exploration.json', 'r') as f:\n",
    "        dtypes = json.load(f)\n",
    "\n",
    "    # save the column data type mappings\n",
    "    dtype_mapping = {}\n",
    "    date_cols = []\n",
    "    for col, dtype in dtypes.items():\n",
    "        if dtype == 'datetime64[ns]':\n",
    "            dtype_mapping[col] = 'object'\n",
    "            date_cols.append(col)\n",
    "        else:\n",
    "            dtype_mapping[col] = dtype\n",
    "\n",
    "    # import the data with specified datatypes\n",
    "    globals()[dataframe] = pd.read_csv(\n",
    "        f'{name}_data_visual_exploration.csv'\n",
    "        ,sep=','\n",
    "        ,index_col=0\n",
    "        ,dtype=dtype_mapping\n",
    "    )\n",
    "\n",
    "    # set the date columns datatype\n",
    "    for date in date_cols:\n",
    "        globals()[dataframe][date] = pd.to_datetime(globals()[dataframe][date])\n",
    "\n",
    "# to avoid the 'is not defined' warning\n",
    "df = df\n",
    "df_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"three-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 1.2. Data Cleaning\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we previously mentioned, there are some columns with weird values:\n",
    "- **Age at Injury**: multiple values below 14, which is the minimum legal age to work in the USA\n",
    "- **WCIO Part Of Body Code**: has a negative value\n",
    "\n",
    "Before we go any further, let's try to tackle these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Age at Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age at Injury'] < 14, 'Age at Injury'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['Age at Injury'] < 14, 'Age at Injury'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    (df['Age at Injury'] < 14) & (df['Accident Date'].isna() | df['Birth Year'].isna()), \n",
    "    'Age at Injury'\n",
    "] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[\n",
    "    (df_test['Age at Injury'] < 14) & (df_test['Accident Date'].isna() | df_test['Birth Year'].isna()), \n",
    "    'Age at Injury'\n",
    "] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the notebook 'Part1-InitialInspection.ipynb', these values cannot yet be fixed, since we are trying to fix them using mathematical logic. Therefore, we will come back to fixing these values after we perform data imputation on the 'Accident Date' and 'Birth Year' columns. If there still are any inconsistent values in the test data, we will set them as NaN and impute them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. WCIO Part Of Body Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42011"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['WCIO Part Of Body Code'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[-9]\n",
       "Length: 1, dtype: Int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['WCIO Part Of Body Code'] < 0]['WCIO Part Of Body Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[-9]\n",
       "Length: 1, dtype: Int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['WCIO Part Of Body Code'] < 0]['WCIO Part Of Body Code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All negative values are the same value - let's check if there are any values '9' or if we can simply convert these values to its absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['WCIO Part Of Body Code'] == 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[df_test['WCIO Part Of Body Code'] == 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are no values that take the value '9', we will convert the negative values to the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCIO Part Of Body Code'] = np.where(\n",
    "    # we select only the rows that meet the necessary conditions\n",
    "    (df['WCIO Part Of Body Code'] < 0) & (df['WCIO Part Of Body Code'].notna()),\n",
    "    # if conditions are met, we calculate the new value\n",
    "    df['WCIO Part Of Body Code'].abs(),\n",
    "    # otherwise, we keep the original value\n",
    "    df['WCIO Part Of Body Code']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['WCIO Part Of Body Code'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['WCIO Part Of Body Code'] = np.where(\n",
    "    # we select only the rows that meet the necessary conditions\n",
    "    (df_test['WCIO Part Of Body Code'] < 0) & (df_test['WCIO Part Of Body Code'].notna()),\n",
    "    # if conditions are met, we calculate the new value\n",
    "    df_test['WCIO Part Of Body Code'].abs(),\n",
    "    # otherwise, we keep the original value\n",
    "    df_test['WCIO Part Of Body Code']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[df_test['WCIO Part Of Body Code'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"four-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 1.3. Missing Values\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "      <th>Total Values</th>\n",
       "      <th>Percentage NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accident Date</th>\n",
       "      <td>3688</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at Injury</th>\n",
       "      <td>5415</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assembly Date</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <td>28651</td>\n",
       "      <td>574022</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Birth Year</th>\n",
       "      <td>31018</td>\n",
       "      <td>574022</td>\n",
       "      <td>5.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Date</th>\n",
       "      <td>14559</td>\n",
       "      <td>574022</td>\n",
       "      <td>2.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Date</th>\n",
       "      <td>386781</td>\n",
       "      <td>574022</td>\n",
       "      <td>67.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Name</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Type</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Injury Type</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County of Injury</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District Name</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Hearing Date</th>\n",
       "      <td>423228</td>\n",
       "      <td>574022</td>\n",
       "      <td>73.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>4757</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IME-4 Count</th>\n",
       "      <td>441219</td>\n",
       "      <td>574022</td>\n",
       "      <td>76.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry Code</th>\n",
       "      <td>9957</td>\n",
       "      <td>574022</td>\n",
       "      <td>1.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <td>15639</td>\n",
       "      <td>574022</td>\n",
       "      <td>2.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <td>15656</td>\n",
       "      <td>574022</td>\n",
       "      <td>2.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <td>17081</td>\n",
       "      <td>574022</td>\n",
       "      <td>2.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip Code</th>\n",
       "      <td>28636</td>\n",
       "      <td>574022</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agreement Reached</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Missed Timing</th>\n",
       "      <td>14559</td>\n",
       "      <td>574022</td>\n",
       "      <td>2.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Missed Timing</th>\n",
       "      <td>386781</td>\n",
       "      <td>574022</td>\n",
       "      <td>67.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days Difference</th>\n",
       "      <td>3688</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Missing</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Missing</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Hearing</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has IME-4 Report</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Age at Injury</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Average Weekly Wage</th>\n",
       "      <td>28651</td>\n",
       "      <td>574022</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Birth Year</th>\n",
       "      <td>31018</td>\n",
       "      <td>574022</td>\n",
       "      <td>5.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log IME-4 Count</th>\n",
       "      <td>441219</td>\n",
       "      <td>574022</td>\n",
       "      <td>76.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Number of Dependents</th>\n",
       "      <td>0</td>\n",
       "      <td>574022</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NaN Count  Total Values Percentage NaN\n",
       "Accident Date                        3688        574022          0.64%\n",
       "Age at Injury                        5415        574022          0.94%\n",
       "Alternative Dispute Resolution          0        574022          0.00%\n",
       "Assembly Date                           0        574022          0.00%\n",
       "Attorney/Representative                 0        574022          0.00%\n",
       "Average Weekly Wage                 28651        574022          4.99%\n",
       "Birth Year                          31018        574022          5.40%\n",
       "C-2 Date                            14559        574022          2.54%\n",
       "C-3 Date                           386781        574022         67.38%\n",
       "Carrier Name                            0        574022          0.00%\n",
       "Carrier Type                            0        574022          0.00%\n",
       "Claim Injury Type                       0        574022          0.00%\n",
       "County of Injury                        0        574022          0.00%\n",
       "COVID-19 Indicator                      0        574022          0.00%\n",
       "District Name                           0        574022          0.00%\n",
       "First Hearing Date                 423228        574022         73.73%\n",
       "Gender                               4757        574022          0.83%\n",
       "IME-4 Count                        441219        574022         76.86%\n",
       "Industry Code                        9957        574022          1.73%\n",
       "Medical Fee Region                      0        574022          0.00%\n",
       "WCIO Cause of Injury Code           15639        574022          2.72%\n",
       "WCIO Nature of Injury Code          15656        574022          2.73%\n",
       "WCIO Part Of Body Code              17081        574022          2.98%\n",
       "Zip Code                            28636        574022          4.99%\n",
       "Agreement Reached                       0        574022          0.00%\n",
       "Number of Dependents                    0        574022          0.00%\n",
       "C-2 Missed Timing                   14559        574022          2.54%\n",
       "C-3 Missed Timing                  386781        574022         67.38%\n",
       "Days Difference                      3688        574022          0.64%\n",
       "C-2 Missing                             0        574022          0.00%\n",
       "C-3 Missing                             0        574022          0.00%\n",
       "Has Hearing                             0        574022          0.00%\n",
       "Has IME-4 Report                        0        574022          0.00%\n",
       "Log Age at Injury                       0        574022          0.00%\n",
       "Log Average Weekly Wage             28651        574022          4.99%\n",
       "Log Birth Year                      31018        574022          5.40%\n",
       "Log IME-4 Count                    441219        574022         76.86%\n",
       "Log Number of Dependents                0        574022          0.00%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the number of NaNs for each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# get the total number of rows\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# calculate the percentage of NaN values for each column\n",
    "percentage_nans = (nan_counts / total_rows) * 100\n",
    "\n",
    "# format the percentages with '%' sign\n",
    "percentage_nans = percentage_nans.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# combine all the information into a DataFrame\n",
    "nan_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts\n",
    "    , 'Total Values': [total_rows] * len(nan_counts)\n",
    "    , 'Percentage NaN': percentage_nans\n",
    "})\n",
    "\n",
    "display(nan_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\n",
    "    'Accident Date'\n",
    "    , 'Average Weekly Wage'\n",
    "    , 'Birth Year'\n",
    "    #, 'C-2 Date'  # missing form could have relationship with the target\n",
    "    #, 'C-3 Date'  # missing form could have relationship with the target\n",
    "    #, 'First Hearing Date'  # missing values means no hearing has held\n",
    "    , 'Gender'\n",
    "    #, 'IME-4 Count'  # missing form could have relationship with the target\n",
    "    , 'Industry Code'\n",
    "    , 'WCIO Cause of Injury Code'\n",
    "    , 'WCIO Nature of Injury Code'\n",
    "    , 'WCIO Part Of Body Code'\n",
    "    , 'Zip Code'\n",
    "    , 'Days Difference'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "      <th>Total Values</th>\n",
       "      <th>Percentage NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accident Date</th>\n",
       "      <td>2444</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at Injury</th>\n",
       "      <td>3123</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assembly Date</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <td>19204</td>\n",
       "      <td>387975</td>\n",
       "      <td>4.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Birth Year</th>\n",
       "      <td>20301</td>\n",
       "      <td>387975</td>\n",
       "      <td>5.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Date</th>\n",
       "      <td>9134</td>\n",
       "      <td>387975</td>\n",
       "      <td>2.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Date</th>\n",
       "      <td>302759</td>\n",
       "      <td>387975</td>\n",
       "      <td>78.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Name</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Type</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County of Injury</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District Name</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Hearing Date</th>\n",
       "      <td>344947</td>\n",
       "      <td>387975</td>\n",
       "      <td>88.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>5613</td>\n",
       "      <td>387975</td>\n",
       "      <td>1.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IME-4 Count</th>\n",
       "      <td>352726</td>\n",
       "      <td>387975</td>\n",
       "      <td>90.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry Code</th>\n",
       "      <td>7736</td>\n",
       "      <td>387975</td>\n",
       "      <td>1.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <td>10348</td>\n",
       "      <td>387975</td>\n",
       "      <td>2.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <td>10560</td>\n",
       "      <td>387975</td>\n",
       "      <td>2.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <td>9549</td>\n",
       "      <td>387975</td>\n",
       "      <td>2.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip Code</th>\n",
       "      <td>19342</td>\n",
       "      <td>387975</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Missed Timing</th>\n",
       "      <td>9134</td>\n",
       "      <td>387975</td>\n",
       "      <td>2.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Missed Timing</th>\n",
       "      <td>302759</td>\n",
       "      <td>387975</td>\n",
       "      <td>78.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days Difference</th>\n",
       "      <td>2444</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Missing</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Missing</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Hearing</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has IME-4 Report</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Age at Injury</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Average Weekly Wage</th>\n",
       "      <td>19204</td>\n",
       "      <td>387975</td>\n",
       "      <td>4.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Birth Year</th>\n",
       "      <td>20301</td>\n",
       "      <td>387975</td>\n",
       "      <td>5.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log IME-4 Count</th>\n",
       "      <td>352726</td>\n",
       "      <td>387975</td>\n",
       "      <td>90.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Number of Dependents</th>\n",
       "      <td>0</td>\n",
       "      <td>387975</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NaN Count  Total Values Percentage NaN\n",
       "Accident Date                        2444        387975          0.63%\n",
       "Age at Injury                        3123        387975          0.80%\n",
       "Alternative Dispute Resolution          0        387975          0.00%\n",
       "Assembly Date                           0        387975          0.00%\n",
       "Attorney/Representative                 0        387975          0.00%\n",
       "Average Weekly Wage                 19204        387975          4.95%\n",
       "Birth Year                          20301        387975          5.23%\n",
       "C-2 Date                             9134        387975          2.35%\n",
       "C-3 Date                           302759        387975         78.04%\n",
       "Carrier Name                            0        387975          0.00%\n",
       "Carrier Type                            0        387975          0.00%\n",
       "County of Injury                        0        387975          0.00%\n",
       "COVID-19 Indicator                      0        387975          0.00%\n",
       "District Name                           0        387975          0.00%\n",
       "First Hearing Date                 344947        387975         88.91%\n",
       "Gender                               5613        387975          1.45%\n",
       "IME-4 Count                        352726        387975         90.91%\n",
       "Industry Code                        7736        387975          1.99%\n",
       "Medical Fee Region                      0        387975          0.00%\n",
       "WCIO Cause of Injury Code           10348        387975          2.67%\n",
       "WCIO Nature of Injury Code          10560        387975          2.72%\n",
       "WCIO Part Of Body Code               9549        387975          2.46%\n",
       "Zip Code                            19342        387975          4.99%\n",
       "Number of Dependents                    0        387975          0.00%\n",
       "C-2 Missed Timing                    9134        387975          2.35%\n",
       "C-3 Missed Timing                  302759        387975         78.04%\n",
       "Days Difference                      2444        387975          0.63%\n",
       "C-2 Missing                             0        387975          0.00%\n",
       "C-3 Missing                             0        387975          0.00%\n",
       "Has Hearing                             0        387975          0.00%\n",
       "Has IME-4 Report                        0        387975          0.00%\n",
       "Log Age at Injury                       0        387975          0.00%\n",
       "Log Average Weekly Wage             19204        387975          4.95%\n",
       "Log Birth Year                      20301        387975          5.23%\n",
       "Log IME-4 Count                    352726        387975         90.91%\n",
       "Log Number of Dependents                0        387975          0.00%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the number of NaNs for each column\n",
    "nan_counts = df_test.isna().sum()\n",
    "\n",
    "# get the total number of rows\n",
    "total_rows = df_test.shape[0]\n",
    "\n",
    "# calculate the percentage of NaN values for each column\n",
    "percentage_nans = (nan_counts / total_rows) * 100\n",
    "\n",
    "# format the percentages with '%' sign\n",
    "percentage_nans = percentage_nans.apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# combine all the information into a DataFrame\n",
    "nan_summary = pd.DataFrame({\n",
    "    'NaN Count': nan_counts\n",
    "    , 'Total Values': [total_rows] * len(nan_counts)\n",
    "    , 'Percentage NaN': percentage_nans\n",
    "})\n",
    "\n",
    "display(nan_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns from the test data that contain missing values are the same as the ones from the train data, with the addition of the descriptive columns, which we had removed from the train data.\n",
    "\n",
    "We will not impute missing values in the commented columns, as per the explainations in the comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"five-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 1.4. Simple Encoding\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['Alternative Dispute Resolution', 'Attorney/Representative', 'Gender', 'COVID-19 Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alternative Dispute Resolution\n",
       "N    571408\n",
       "Y      2609\n",
       "U         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Alternative Dispute Resolution\n",
       "N    386314\n",
       "Y      1660\n",
       "U         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Attorney/Representative\n",
       "N    392291\n",
       "Y    181731\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Attorney/Representative\n",
       "N    306476\n",
       "Y     81499\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "M    335216\n",
       "F    234049\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "M    215343\n",
       "F    167019\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "COVID-19 Indicator\n",
       "N    546504\n",
       "Y     27518\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "COVID-19 Indicator\n",
       "N    385434\n",
       "Y      2541\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in binary_columns:\n",
    "    display(df[col].value_counts())\n",
    "    display(df_test[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed with the encoding of these features, let us replace the value 'U' in 'Alternative Dispute Resolution', by setting it as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Alternative Dispute Resolution'] == 'U', 'Alternative Dispute Resolution'] = np.nan\n",
    "df_test.loc[df_test['Alternative Dispute Resolution'] == 'U', 'Alternative Dispute Resolution'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding binary features\n",
    "for col in binary_columns:\n",
    "    df[col] = df[col].map({'Y': 1, 'N': 0, 'M': 1, 'F': 0})\n",
    "    df_test[col] = df_test[col].map({'Y': 1, 'N': 0, 'M': 1, 'F': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dates(df, date_columns):\n",
    "    for col in date_columns:\n",
    "        df[f'{col}_year'] = df[col].apply(lambda x: x.year if pd.notnull(x) else np.nan)\n",
    "        df[f'{col}_month'] = df[col].apply(lambda x: x.month if pd.notnull(x) else np.nan)\n",
    "        df[f'{col}_day'] = df[col].apply(lambda x: x.day if pd.notnull(x) else np.nan)\n",
    "\n",
    "    # Drop the original date columns\n",
    "    df.drop(columns=date_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_features = [\n",
    "    'Accident Date'\n",
    "    , 'Assembly Date'\n",
    "    , 'C-2 Date'\n",
    "    , 'C-3 Date'\n",
    "    , 'First Hearing Date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation\n",
    "encode_dates(df, date_features)\n",
    "encode_dates(df_test, date_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"six-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 1.5. Pipeline Preparation\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Claim Injury Type', 'Agreement Reached'])\n",
    "y = df['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers Treatment - Capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipOutliersMulti(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, quantile_limits=None, fixed_limits=None):\n",
    "        \"\"\"\n",
    "        quantile_limits: dictionary with quantile-based limits. Example:\n",
    "            {'Age at Injury': (0.01, 0.95), 'Birth Year': (0.01, 0.95)}\n",
    "\n",
    "        fixed_limits: dictionary with fixed limits. Example:\n",
    "            {'IME-4 Count': (None, 40)}\n",
    "        \"\"\"\n",
    "        self.quantile_limits = quantile_limits or {}\n",
    "        self.fixed_limits = fixed_limits or {}\n",
    "        self.bounds = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate limits based on quantiles\n",
    "        for col, (q_lower, q_upper) in self.quantile_limits.items():\n",
    "            self.bounds[col] = {\n",
    "                'lower': X[col].quantile(q_lower) if q_lower is not None else None,\n",
    "                'upper': X[col].quantile(q_upper) if q_upper is not None else None\n",
    "            }\n",
    "\n",
    "        # Add fixed limits\n",
    "        for col, (lower, upper) in self.fixed_limits.items():\n",
    "            self.bounds[col] = {\n",
    "                'lower': lower,\n",
    "                'upper': upper\n",
    "            }\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Clip values based on the calculated or fixed bounds\n",
    "        X = X.copy()\n",
    "        for col, limits in self.bounds.items():\n",
    "            X[col] = X[col].astype(float).clip(lower=limits['lower'], upper=limits['upper'])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        \"\"\"\n",
    "        columns: List of categorical columns to apply frequency encoding.\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.freq_encodings = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Check if X is a DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"FrequencyEncoder requires a pandas DataFrame as input.\")\n",
    "        \n",
    "        # Calculate frequency encoding for each column\n",
    "        for col in self.columns:\n",
    "            if col not in X.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in input DataFrame.\")\n",
    "            # Only normalized values (removes named indexes)\n",
    "            self.freq_encodings[col] = X[col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Check if X is a DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"FrequencyEncoder requires a pandas DataFrame as input.\")\n",
    "        \n",
    "        X = X.copy()\n",
    "        # Apply frequency mapping\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].map(self.freq_encodings[col]).fillna(0)  # Fill non-mapped values with 0\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder for the target variable\n",
    "target_encoder = OrdinalEncoder()\n",
    "\n",
    "# Encode the target\n",
    "y_encoded = target_encoder.fit_transform(y.to_numpy().reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalling and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_features = [\n",
    "    'Age at Injury',\n",
    "    'Average Weekly Wage',\n",
    "    'Birth Year',\n",
    "    'IME-4 Count',\n",
    "    #'Industry Code',\n",
    "    #'WCIO Cause of Injury Code',\n",
    "    #'WCIO Nature of Injury Code',\n",
    "    #'WCIO Part Of Body Code',\n",
    "    'Number of Dependents',\n",
    "    'Days Difference',\n",
    "    'Accident Date_year', 'Accident Date_month', 'Accident Date_day',\n",
    "    'Assembly Date_year', 'Assembly Date_month', 'Assembly Date_day',\n",
    "    'C-2 Date_year', 'C-2 Date_month', 'C-2 Date_day',\n",
    "    'C-3 Date_year', 'C-3 Date_month', 'C-3 Date_day',\n",
    "    'First Hearing Date_year', 'First Hearing Date_month', 'First Hearing Date_day'\n",
    "]\n",
    "\n",
    "# List of features for One-Hot encoding\n",
    "lowcard_features = ['Carrier Type', 'District Name', 'Medical Fee Region']\n",
    "\n",
    "# Set up the preprocessor with scaling and OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', MinMaxScaler(), scaling_features),  # Apply scaling to the specified features\n",
    "        ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first'), lowcard_features)  # Apply One-Hot encoding to low-cardinality features\n",
    "    ],\n",
    "    remainder='passthrough',  # Keep columns not specified\n",
    "    verbose_feature_names_out=False  # Do not rename the columns\n",
    ").set_output(transform=\"pandas\")  # Ensure the output is a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values Imputation - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleKNNImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, n_neighbors=5, weights='distance', sample_size=30000, random_state=20):\n",
    "        \"\"\"\n",
    "        features: List of columns to be imputed.\n",
    "        n_neighbors: Number of neighbors for the KNNImputer.\n",
    "        sample_size: Number of samples for fitting the imputer.\n",
    "        random_state: Random seed for sampling control.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.sample_size = sample_size\n",
    "        self.random_state = random_state\n",
    "        self.imputer = KNNImputer(n_neighbors=self.n_neighbors, weights=self.weights)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Rebuild DataFrame if X is a NumPy array\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.features)\n",
    "\n",
    "        # Select a sample to fit the imputer\n",
    "        sample = X[self.features].sample(n=self.sample_size, random_state=self.random_state)\n",
    "        self.imputer.fit(sample)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Rebuild DataFrame if X is a NumPy array\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.features)\n",
    "\n",
    "        # Impute missing values\n",
    "        X[self.features] = self.imputer.transform(X[self.features])\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values Imputation - Zero Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroFillImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        features: List of columns that should be filled with zero.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting logic is required\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.features] = X[self.features].fillna(0)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputerGridSearch:\n",
    "    def __init__(self, pipeline, imputer_param_grid, random_state=20):\n",
    "        \"\"\"\n",
    "        Initializes the ImputerGridSearch object.\n",
    "        \n",
    "        pipeline: The pipeline that includes the imputer and other steps.\n",
    "        imputer_param_grid: Dictionary containing the parameter grid for the imputer.\n",
    "        random_state: Random seed for reproducibility (default is 20).\n",
    "        \"\"\"\n",
    "        self.pipeline = pipeline\n",
    "        self.imputer_param_grid = imputer_param_grid\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def perform_grid_search(self, data, cv, y):\n",
    "        \"\"\"\n",
    "        Perform grid search on the pipeline with the imputer parameters.\n",
    "        \n",
    "        data: The input data for training.\n",
    "        cv: Cross-validation strategy (KFold).\n",
    "        y: The target variable (labels).\n",
    "        \n",
    "        Returns the best model found during grid search.\n",
    "        \"\"\"\n",
    "        best_params = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        # Define the parameter grid for the imputer step in the pipeline\n",
    "        param_grid = {\n",
    "            'imputer__n_neighbors': self.imputer_param_grid['n_neighbors'],  # Number of neighbors for KNN\n",
    "            'imputer__weights': self.imputer_param_grid['weights']  # Weights for KNN imputation\n",
    "        }\n",
    "\n",
    "        # Set up GridSearchCV to search for the best hyperparameters\n",
    "        grid_search = GridSearchCV(\n",
    "            self.pipeline,  # The pipeline to be optimized\n",
    "            param_grid,  # The parameter grid to search\n",
    "            scoring='f1_macro',  # Evaluate using F1 score (macro average)\n",
    "            cv=cv,  # Cross-validation strategy\n",
    "            verbose=3,  # Display detailed information during the search\n",
    "            n_jobs=-1  # Use all available CPU cores\n",
    "        )\n",
    "\n",
    "        # Perform grid search\n",
    "        grid_search.fit(data, y)\n",
    "\n",
    "        # Store the best parameters and best score found\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "\n",
    "        # Print the results of the grid search\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Best Test Score: {best_score:.4f}\")\n",
    "\n",
    "        # Return the pipeline with the best parameters\n",
    "        return self.pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"seven-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "## 2. Feature Selection\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"eight-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 2.1. Spearman Correlation\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveHighSpearmanCorrelation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, threshold=0.8):\n",
    "        \"\"\"\n",
    "        Remove highly correlated variables based on Spearman correlation.\n",
    "\n",
    "        Parameters:\n",
    "        - features: List of numeric variables to be analyzed.\n",
    "        - threshold: Limit above which variables will be considered correlated.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.threshold = threshold\n",
    "        self.to_remove = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Calculates the correlation and identifies the variables to be removed.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input DataFrame.\n",
    "        - y: Ignored (for compatibility with sklearn).\n",
    "        \"\"\"\n",
    "        # Calculate the correlation matrix for the specified variables\n",
    "        corr_matrix = X[self.features].corr(method='spearman')\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "        # Identify variables with high correlation\n",
    "        self.to_remove = [\n",
    "            column for column in upper_triangle.columns \n",
    "            if any(upper_triangle[column] > self.threshold)\n",
    "        ]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Removes the identified variables.\n",
    "\n",
    "        \"\"\"\n",
    "        return X.drop(columns=self.to_remove, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nine-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 2.2. XGBoost\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_features=18, model=None, random_state=42):\n",
    "        \"\"\"\n",
    "        num_features: Number of most important features to select.\n",
    "        model: Model to be used for calculating feature importance.\n",
    "        random_state: Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.num_features = num_features\n",
    "        self.model = model if model else XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            scale_pos_weight=1,\n",
    "            random_state=random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        self.random_state = random_state  # Adds random_state as an internal attribute\n",
    "        self.top_features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the model to calculate feature importance\n",
    "        self.model.fit(X, y)\n",
    "        # Select the N most important features\n",
    "        feature_importances = pd.Series(self.model.feature_importances_, index=X.columns)\n",
    "        self.top_features = feature_importances.nlargest(self.num_features).index\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Return only the selected features\n",
    "        return X[self.top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ten-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 2.3. Decision Trees\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection with Decision Trees. By using the module __.feature_importances___ we can calculate the feature importance using the split criteria 'gini' and 'entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT_FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, gini_threshold=0.005, entropy_threshold=0.005, random_state=42):\n",
    "        \"\"\"\n",
    "        num_features: Maximum number of features to select.\n",
    "        gini_threshold: Minimum importance threshold for the Gini criterion.\n",
    "        entropy_threshold: Minimum importance threshold for the Entropy criterion.\n",
    "        random_state: Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.gini_threshold = gini_threshold\n",
    "        self.entropy_threshold = entropy_threshold\n",
    "        self.random_state = random_state\n",
    "        self.top_features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Model with Gini criterion\n",
    "        gini_model = DecisionTreeClassifier(criterion='gini', random_state=self.random_state)\n",
    "        gini_model.fit(X, y)\n",
    "        gini_importance = pd.Series(gini_model.feature_importances_, index=X.columns)\n",
    "        \n",
    "        # Model with Entropy criterion\n",
    "        entropy_model = DecisionTreeClassifier(criterion='entropy', random_state=self.random_state)\n",
    "        entropy_model.fit(X, y)\n",
    "        entropy_importance = pd.Series(entropy_model.feature_importances_, index=X.columns)\n",
    "\n",
    "        # Combine the importances into a DataFrame\n",
    "        feature_importances = pd.DataFrame({\n",
    "            'gini': gini_importance,\n",
    "            'entropy': entropy_importance\n",
    "        })\n",
    "\n",
    "        # Melt the DataFrame to long format and filter based on the thresholds\n",
    "        feature_importances['feature'] = X.columns\n",
    "        tidy = feature_importances.melt(id_vars='feature', var_name='criterion', value_name='importance')\n",
    "        tidy = tidy[tidy['importance'] > 0]  # Remove zero importances\n",
    "\n",
    "        # Filter features that pass the thresholds\n",
    "        selected_features = tidy[((tidy['criterion'] == 'gini') & (tidy['importance'] > self.gini_threshold)) |\n",
    "                                  ((tidy['criterion'] == 'entropy') & (tidy['importance'] > self.entropy_threshold))]\n",
    "\n",
    "        # Sort by importance and select the N best features\n",
    "        selected_features = selected_features.sort_values(by='importance', ascending=False)\n",
    "        self.top_features = selected_features['feature'].unique()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Return only the selected features\n",
    "        if self.top_features is None:\n",
    "            raise RuntimeError(\"The fit method needs to be called before transform.\")\n",
    "        return X[self.top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"eleven-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "## 3. Model Assessment\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twelve-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.1. Pre Model \n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dataframe(X):\n",
    "    # Ensures that the input is a pandas DataFrame; if not, converts it to one\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        return pd.DataFrame(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_columns(X):\n",
    "    # Prints the list of columns after preprocessing\n",
    "    print(f\"Columns after preprocessor: {list(X.columns)}\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_mapping = {\n",
    "    'Industry Code': {\n",
    "        'Primary Industry': [11, 21, 22]  # Raw materials\n",
    "        ,'Secondary Industry': [23, 31]  # Manufacturing and Production\n",
    "        ,'Tertiary Industry': [42, 44, 48, 53]  # Services\n",
    "        ,'Quaternary Industry': [51, 52, 54, 55]  # Knowledge-based\n",
    "        ,'Social and Public Services': [61, 62, 92]\n",
    "        ,'Recreational and Hospitality Services': [71, 72]\n",
    "        ,'Other Services': [56, 81]\n",
    "    }\n",
    "    ,'WCIO Part Of Body Code': {\n",
    "        'Head': range(10, 20)\n",
    "        ,'Neck': range(20, 27)\n",
    "        ,'Upper Extremities': range(30, 40)\n",
    "        ,'Trunk': [*range(40, 50), *range(60, 64)]\n",
    "        ,'Lower Extremities': range(50, 59)\n",
    "        ,'Multiple Body Parts': [9, *range(64, 67), 90, 91, 99]\n",
    "    }\n",
    "    ,'WCIO Nature of Injury Code': {\n",
    "        'Specific Injury': [1, 2, 3, 4, 7, 10, 13, 16, 19, 22, 25, 28, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 46, 47, 49, 52, 53, 54, 55, 58, 59]\n",
    "        ,'Occupational Disease or Cumulative Injury': [*range(60, 81), 83]\n",
    "        ,'Multiple Injuries': [90, 91]\n",
    "    }\n",
    "    ,'WCIO Cause of Injury Code': {\n",
    "        'Burn or Scald - Heat or Cold Exposures - Contact With': [*range(1, 10), 11, 14, 84]\n",
    "        ,'Caught In, Under or Between': [10, 12, 13, 20]\n",
    "        ,'Cut, Puncture, Scrape Injured By': range(15, 20)\n",
    "        ,'Fall, Slip or Trip Injury': range(25, 34)\n",
    "        ,'Motor Vehicle': [40, 41, *range(45, 49), 50]\n",
    "        ,'Strain or Injury By': [*range(52, 62), 97]\n",
    "        ,'Stricking Against or Stepping On': range(65, 71)\n",
    "        ,'Struck or Injured By': [*range(74, 82), 85, 86]\n",
    "        ,'Rubbed or Abraded By': [94, 95]\n",
    "        ,'Miscellaneous Causes': [82, 83, *range(87, 92), 93, 96, 98, 99]\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mappings Reference:\n",
    "- https://www.dir.ca.gov/dwc/WCIS/Part_of_Body.pdf\n",
    "- https://www.dir.ca.gov/dwc/WCIS/Nature_Of_Injury.pdf\n",
    "- https://www.dir.ca.gov/dwc/WCIS/Cause_Of_Injury.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mapping_dict):\n",
    "        \"\"\"\n",
    "        Initializes the CodeMapper with a dictionary containing the mapping information.\n",
    "        \"\"\"\n",
    "        self.mapping_dict = mapping_dict\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms the input data by applying the specified mappings to the relevant columns.\n",
    "        \"\"\"\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        # Loop through the columns and apply the reverse mappings\n",
    "        for col, mappings in self.mapping_dict.items():\n",
    "            # Reverse the mapping to map values to their corresponding keys\n",
    "            reverse_mapping = {\n",
    "                val: key \n",
    "                for key, values in mappings.items() \n",
    "                for val in values\n",
    "            }\n",
    "\n",
    "            # Apply the mapping to the column and keep the original value if no mapping is found\n",
    "            X_transformed[col] = X_transformed[col].map(reverse_mapping).fillna(X_transformed[col])\n",
    "\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertDataType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dtype, columns):\n",
    "        \"\"\"\n",
    "        Initializes the transformer to change the data type of specified columns.\n",
    "        \"\"\"\n",
    "        self.dtype = dtype\n",
    "        self.columns = columns\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms the data by converting specified columns to the target data type.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].astype(self.dtype)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixCodes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, valid_codes, columns):\n",
    "        \"\"\"\n",
    "        Initializes the transformer to fix codes based on the closest valid value.\n",
    "        \"\"\"\n",
    "        self.valid_codes = valid_codes\n",
    "        self.columns = columns\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms the data by replacing invalid codes with the closest valid value.\n",
    "        \"\"\"\n",
    "        def closest_valid_value(col, val):\n",
    "            \"\"\"\n",
    "            Finds the closest valid value for a given invalid code.\n",
    "            \"\"\"\n",
    "            valid_values = []\n",
    "\n",
    "            for category, values in self.valid_codes[col].items():\n",
    "                valid_values.extend(values)\n",
    "\n",
    "            if val in valid_values:\n",
    "                return val\n",
    "            else:\n",
    "                return min(valid_values, key=lambda x: abs(x - val))\n",
    "            \n",
    "\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        for col in self.columns:\n",
    "            X_transformed[col] = X[col].apply(lambda x: closest_valid_value(col, x))\n",
    "\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializing kf with StratifiedKFold that will be used in the rest of the notebook\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_intervals(pipeline, X, y, feature_intervals, scoring='f1_macro', cv=5):\n",
    "    \"\"\"\n",
    "    Evaluates different numbers of features in the pipeline using Stratified K-Fold CV.\n",
    "    \n",
    "    Parameters:\n",
    "    - pipeline: Sklearn pipeline with EmbeddedFeatureSelector.\n",
    "    - X: DataFrame of features.\n",
    "    - y: Target variable.\n",
    "    - feature_intervals: List of numbers of features to test.\n",
    "    - scoring: Evaluation metric (default: 'f1_macro').\n",
    "    - cv: Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with the results (n_features, mean_train_score, mean_val_score, overfit).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    for num_features in feature_intervals:\n",
    "        # Update the number of features in the selector within the pipeline\n",
    "        pipeline.set_params(feature_selector__num_features=num_features)\n",
    "        \n",
    "        # Perform cross-validation with StratifiedKFold\n",
    "        scores = cross_validate(\n",
    "            pipeline, X, y, cv=skf, scoring=scoring, n_jobs=-1, return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'n_features': num_features,\n",
    "            'mean_train_score': scores['train_score'].mean(),\n",
    "            'mean_val_score': scores['test_score'].mean(),\n",
    "            'overfit': abs(scores['train_score'].mean() - scores['test_score'].mean())\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, X, y):\n",
    "    \"\"\"\n",
    "    This function receives a model, the X and y data, and applies cross-validation\n",
    "    using StratifiedKFold to calculate the F1 score for both training and validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lists to store the results of time and F1 score\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "\n",
    "    # Loop through the StratifiedKFold splits\n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        # Get the training and validation data for each split\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Calculate the F1-score for the training data\n",
    "        train_predictions = model.predict(X_train_fold)\n",
    "        train_f1 = f1_score(y_train_fold, train_predictions, average='macro')  # Adjusted for multiclass\n",
    "        \n",
    "        # Calculate the F1-score for the validation data\n",
    "        val_predictions = model.predict(X_val_fold)\n",
    "        val_f1 = f1_score(y_val_fold, val_predictions, average='macro')  # Adjusted for multiclass\n",
    "        \n",
    "        # Store the results in the lists\n",
    "        train_f1_scores.append(train_f1)\n",
    "        val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Calculate the averages of each metric\n",
    "    avg_train_f1 = np.mean(train_f1_scores)\n",
    "    avg_val_f1 = np.mean(val_f1_scores)\n",
    "\n",
    "    # Return the results formatted\n",
    "    return avg_train_f1, avg_val_f1\n",
    "\n",
    "\n",
    "def show_results(df, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # For each model passed as an argument\n",
    "    for arg in args:\n",
    "        # Obtain the results provided by avg_score\n",
    "        avg_train, avg_val = avg_score(arg, X, pd.DataFrame(y_encoded))\n",
    "        # Store the results in the correct row\n",
    "        df.iloc[count] = avg_train, avg_val\n",
    "        count+=1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the process of testing models, we run a grid search to find the best parameters to use on the imputer, based on the f1 score macro on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter grid for the imputer\n",
    "# imputer_param_grid = {\n",
    "#     'n_neighbors': [5, 10, 15],  # Number of neighbors for KNN imputation\n",
    "#     'weights': ['uniform', 'distance']  # Weighting method for neighbors\n",
    "# }\n",
    "\n",
    "# Sample 30000 random samples from the data for imputation\n",
    "# imp_X = X.copy().reset_index(drop=True).sample(30000, random_state=20)\n",
    "# imp_y = y_encoded[imp_X.index.values]\n",
    "\n",
    "# int64_columns = imp_X.select_dtypes(include='Int64').columns\n",
    "# imp_X[int64_columns] = imp_X[int64_columns].astype(float)\n",
    "\n",
    "# # Initialize the ImputerGridSearch class with a pipeline and the parameter grid\n",
    "# imputer_search = ImputerGridSearch(\n",
    "#     pipeline=Pipeline(steps=[  # Sequential pipeline of transformations and model fitting\n",
    "#         ('clip_outliers', ClipOutliersMulti(\n",
    "#             quantile_limits={  # Setting quantile-based limits for clipping outliers\n",
    "#                 'Age at Injury': (0.01, 0.95),\n",
    "#                 'Average Weekly Wage': (None, 0.75),\n",
    "#                 'Birth Year': (0.01, 0.95),\n",
    "#                 'Days Difference': (None, 0.80),\n",
    "#             },\n",
    "#             fixed_limits={  # Fixed limits for clipping outliers\n",
    "#                 'IME-4 Count': (None, 40)\n",
    "#             }\n",
    "#         )),\n",
    "#         ('preprocessor', preprocessor),  # Scaling and OneHot encoding\n",
    "#         ('frequency_encoder', FrequencyEncoder(columns=[  # Encoding categorical features by frequency\n",
    "#             'Carrier Name', 'County of Injury', 'Zip Code'\n",
    "#         ])),\n",
    "#         ('imputer', SampleKNNImputer(\n",
    "#             features=[  # Features to be imputed\n",
    "#                 'Alternative Dispute Resolution', 'Average Weekly Wage', 'Age at Injury', 'Birth Year',\n",
    "#                 'Carrier Name', 'Gender', 'Industry Code', 'WCIO Cause of Injury Code',\n",
    "#                 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code',\n",
    "#                 'Accident Date_year', 'Accident Date_month', 'Accident Date_day', 'Days Difference'\n",
    "#             ],\n",
    "#             n_neighbors=10, sample_size=10000, random_state=20\n",
    "#         )),\n",
    "#         ('int_convert', ConvertDataType(dtype='int', columns=['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])),\n",
    "#         ('fix_codes', FixCodes(valid_codes=code_mapping, columns=['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])),\n",
    "#         ('zero_fill', ZeroFillImputer(features=[  # Filling missing values with zeros for specific columns\n",
    "#             'IME-4 Count', 'C-2 Date_year', 'C-2 Date_month', 'C-2 Date_day',\n",
    "#             'C-3 Date_year', 'C-3 Date_month', 'C-3 Date_day',\n",
    "#             'First Hearing Date_year', 'First Hearing Date_month', 'First Hearing Date_day'\n",
    "#         ])),\n",
    "#         ('code_mapping', CodeMapper(code_mapping)),\n",
    "#         ('oh_codes', ColumnTransformer(transformers=[\n",
    "#             ('onehot', OneHotEncoder(\n",
    "#                 sparse_output=False\n",
    "#                 ,handle_unknown='ignore'\n",
    "#                 ,drop='first'\n",
    "#             ), ['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])\n",
    "#         ], remainder='passthrough'  # Preserve unspecified columns\n",
    "#         ,verbose_feature_names_out=False  # Do not rename columns\n",
    "#         ).set_output(transform=\"pandas\")),\n",
    "#         ('model', XGBClassifier(  # The model used for classification\n",
    "#             n_estimators=200,\n",
    "#             max_depth=6,\n",
    "#             learning_rate=0.1,\n",
    "#             reg_alpha=5,\n",
    "#             reg_lambda=10,\n",
    "#             random_state=42\n",
    "#         ))\n",
    "#     ])\n",
    "#     ,imputer_param_grid=imputer_param_grid  # Passing the hyperparameter grid for imputation\n",
    "# )\n",
    "\n",
    "# # Perform grid search on the pipeline using the defined cross-validation and sample data\n",
    "# imputer_search.perform_grid_search(\n",
    "#     data=imp_X,\n",
    "#     cv=kf,\n",
    "#     y=imp_y\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the parameters that return a higher f1 score macro, we define a variable which contains all the steps common to every model we shall test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_steps = [\n",
    "    ('clip_outliers', ClipOutliersMulti(\n",
    "            quantile_limits={\n",
    "                'Age at Injury': (0.01, 0.95),\n",
    "                'Average Weekly Wage': (None, 0.75),  \n",
    "                'Birth Year': (0.01, 0.95),\n",
    "                'Days Difference': (None, 0.80),\n",
    "            },\n",
    "            fixed_limits={\n",
    "                'IME-4 Count': (None, 40)\n",
    "            }\n",
    "        )),\n",
    "        ('preprocessor', preprocessor),  #Scalling and one hot encoding\n",
    "        ('frequency_encoder', FrequencyEncoder(columns=[\n",
    "            'Carrier Name', 'County of Injury', 'Zip Code'\n",
    "        ])),\n",
    "        ('imputer', SampleKNNImputer(\n",
    "            features=[\n",
    "                'Alternative Dispute Resolution', 'Average Weekly Wage', 'Age at Injury','Birth Year', 'Carrier Name', 'Gender',\n",
    "                'Zip Code', 'Accident Date_year', 'Accident Date_month', 'Accident Date_day', 'Days Difference',\n",
    "                'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code',\n",
    "                'C-2 Missed Timing', 'C-3 Missed Timing', 'Log Average Weekly Wage', 'Log Birth Year', 'Log IME-4 Count'\n",
    "            ],\n",
    "            n_neighbors=5, weights='uniform', sample_size=1000, random_state=20\n",
    "        )),\n",
    "        ('int_convert', ConvertDataType(dtype='int', columns=['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])),\n",
    "        ('fix_codes', FixCodes(valid_codes=code_mapping, columns=['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])),\n",
    "        ('zero_fill', ZeroFillImputer(features=[\n",
    "            'IME-4 Count', 'C-2 Date_year', 'C-2 Date_month', 'C-2 Date_day',\n",
    "            'C-3 Date_year', 'C-3 Date_month', 'C-3 Date_day',\n",
    "            'First Hearing Date_year', 'First Hearing Date_month', 'First Hearing Date_day'\n",
    "        ])),\n",
    "        ('code_mapping', CodeMapper(code_mapping)),\n",
    "        ('oh_codes', ColumnTransformer(transformers=[\n",
    "            ('onehot', OneHotEncoder(\n",
    "                sparse_output=False\n",
    "                ,handle_unknown='ignore'\n",
    "                ,drop='first'\n",
    "            ), ['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code'])\n",
    "        ], remainder='passthrough'  # Preserve unspecified columns\n",
    "        ,verbose_feature_names_out=False  # Do not rename columns\n",
    "        ).set_output(transform=\"pandas\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"thirteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.2. XGBoost\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Pipeline Construction with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_XGB = Pipeline(steps=[\n",
    "    *preproc_steps,\n",
    "    ('feature_selector', XGBFeatureSelector(num_features=53)),  # Feature Selection\n",
    "    ('model', XGBClassifier(  # Final Model\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        reg_alpha=5,\n",
    "        reg_lambda=10,\n",
    "        random_state=42,\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to decide the number of features on the XGBoost Feature Selector? We will anlyse the f1-macro scores on the train and test folds with the different number of features below on the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Deciding the number of features to mantain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since testing every number of features would be very computationally expensive, we ran some ranges and we understood the best number would be between 50-60. With best number we mean the best combination between overfit and the f1-macro validation score. Since the f1-macro would not increase as much as overfit when the number of features was changed, we decided to keep a maximum of 2 or 3 percentual points of difference between scores to control overfit and then trying to maximize validation score, which was 53 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_intervals = range(45, 60)\n",
    "\n",
    "# results_df = evaluate_feature_intervals(pipeline_XGB, X, y_encoded, feature_intervals, scoring='f1_macro', cv=5)\n",
    "\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_features</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_val_score</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.453409</td>\n",
       "      <td>0.431743</td>\n",
       "      <td>0.021666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.454285</td>\n",
       "      <td>0.430338</td>\n",
       "      <td>0.023947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.431194</td>\n",
       "      <td>0.024409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.455846</td>\n",
       "      <td>0.431260</td>\n",
       "      <td>0.024587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.456972</td>\n",
       "      <td>0.432816</td>\n",
       "      <td>0.024156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>0.456905</td>\n",
       "      <td>0.431282</td>\n",
       "      <td>0.025623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  n_features  mean_train_score  mean_val_score   overfit\n",
       "0           0          53          0.453409        0.431743  0.021666\n",
       "1           1          54          0.454285        0.430338  0.023947\n",
       "2           2          55          0.455603        0.431194  0.024409\n",
       "3           3          56          0.455846        0.431260  0.024587\n",
       "4           4          57          0.456972        0.432816  0.024156\n",
       "5           5          58          0.456905        0.431282  0.025623"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_select = pd.read_csv('Feature Selection XGB')\n",
    "feat_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running some tests we noticed that when implementing feature selection based on spearman correlation our model was overfitting more than without it. We are going to understand why by comparing the correlated features with the feature importance attributed by XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4. Model-Based Feature Selection - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Average Weekly Wage                                                 0.206959\n",
      "Average Weekly Wage                                                     0.146460\n",
      "C-2 Missing                                                             0.118469\n",
      "Attorney/Representative                                                 0.107266\n",
      "Alternative Dispute Resolution                                          0.072183\n",
      "Has IME-4 Report                                                        0.044110\n",
      "WCIO Part Of Body Code_Trunk                                            0.032377\n",
      "Has Hearing                                                             0.015991\n",
      "Carrier Type_3A. SELF PUBLIC                                            0.013757\n",
      "Carrier Type_UNKNOWN                                                    0.012830\n",
      "COVID-19 Indicator                                                      0.012763\n",
      "C-2 Missed Timing                                                       0.011936\n",
      "IME-4 Count                                                             0.011703\n",
      "C-2 Date_year                                                           0.010605\n",
      "C-3 Missed Timing                                                       0.010282\n",
      "Accident Date_year                                                      0.009288\n",
      "WCIO Part Of Body Code_Upper Extremities                                0.008955\n",
      "District Name_NYC                                                       0.008889\n",
      "Carrier Type_2A. SIF                                                    0.008504\n",
      "WCIO Part Of Body Code_Lower Extremities                                0.008357\n",
      "First Hearing Date_year                                                 0.007365\n",
      "C-3 Missing                                                             0.007039\n",
      "Carrier Type_5D. SPECIAL FUND - UNKNOWN                                 0.006746\n",
      "WCIO Cause of Injury Code_Miscellaneous Causes                          0.006546\n",
      "WCIO Part Of Body Code_Multiple Body Parts                              0.006244\n",
      "WCIO Cause of Injury Code_Strain or Injury By                           0.006164\n",
      "WCIO Part Of Body Code_Neck                                             0.005820\n",
      "Assembly Date_year                                                      0.005717\n",
      "WCIO Nature of Injury Code_Occupational Disease or Cumulative Injury    0.005211\n",
      "WCIO Cause of Injury Code_Cut, Puncture, Scrape Injured By              0.005125\n",
      "Log IME-4 Count                                                         0.004615\n",
      "Carrier Name                                                            0.004514\n",
      "Days Difference                                                         0.004215\n",
      "District Name_ROCHESTER                                                 0.003850\n",
      "Industry Code_Tertiary Industry                                         0.003786\n",
      "Industry Code_Social and Public Services                                0.003496\n",
      "C-3 Date_year                                                           0.003488\n",
      "Industry Code_Secondary Industry                                        0.003472\n",
      "District Name_STATEWIDE                                                 0.003276\n",
      "District Name_BINGHAMTON                                                0.003213\n",
      "WCIO Cause of Injury Code_Motor Vehicle                                 0.003194\n",
      "Gender                                                                  0.003081\n",
      "District Name_BUFFALO                                                   0.002701\n",
      "WCIO Nature of Injury Code_Specific Injury                              0.002351\n",
      "District Name_HAUPPAUGE                                                 0.002308\n",
      "Carrier Type_4A. SELF PRIVATE                                           0.002294\n",
      "Medical Fee Region_IV                                                   0.002290\n",
      "WCIO Cause of Injury Code_Fall, Slip or Trip Injury                     0.001991\n",
      "County of Injury                                                        0.001906\n",
      "District Name_SYRACUSE                                                  0.001779\n",
      "Log Age at Injury                                                       0.001654\n",
      "WCIO Cause of Injury Code_Struck or Injured By                          0.001486\n",
      "Medical Fee Region_UK                                                   0.001378\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Process only the first fold and extract important features\n",
    "features_first_fold = None\n",
    "\n",
    "# Process only the first fold and extract important features\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y_encoded)):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    # Fit the pipeline on the training set\n",
    "    pipeline_XGB.fit(X_train, y_train)\n",
    "\n",
    "    # Extract the feature selector and model from the pipeline\n",
    "    feature_selector = pipeline_XGB.named_steps['feature_selector']\n",
    "    model = pipeline_XGB.named_steps['model']\n",
    "\n",
    "    # Get selected feature names from the feature selector\n",
    "    selected_feature_names = feature_selector.top_features  # Use directly as names\n",
    "\n",
    "    # Get feature importances from the model\n",
    "    feature_importances = pd.Series(\n",
    "        model.feature_importances_,\n",
    "        index=selected_feature_names\n",
    "    ).sort_values(ascending=False)\n",
    "\n",
    "    # Display the features and their importances\n",
    "    print(feature_importances)\n",
    "\n",
    "    # Break after processing the first fold\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can understand why: spearman removes 'C-2 Date_year' which is the 14th most important variable, even if the relative importance to the model is not very big. For XGBoost we will stick to the feature importance attributed by the model itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the first fold\n",
    "for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # Fit the pipeline on the training fold\n",
    "    pipeline_XGB.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = pipeline_XGB.predict(X_val)\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # Display the matrix graphically\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline_XGB.classes_, yticklabels=pipeline_XGB.classes_)\n",
    "    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the class 1 relatively well while the others not really, for example classes 5 and 6 are always predicted wrongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.6. F1-Macro, Recall-Macro and Precision-Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1-Macro scores for each fold: [0.45566565 0.45135301 0.4555698  0.45164359 0.45281232]\n",
      "Validation F1-Macro scores for each fold: [0.42141063 0.44026321 0.42801034 0.43995116 0.42907901]\n",
      "Mean Train F1-Macro score: 0.4534088734355253\n",
      "Mean Validation F1-Macro score: 0.4317428686988401\n",
      "Std Dev Train F1-Macro score: 0.0018687599946841502\n",
      "Std Dev Validation F1-Macro score: 0.007317860772227768\n",
      "\n",
      "Mean Train Recall-Macro score: 0.4315049348731413\n",
      "Mean Validation Recall-Macro score: 0.41325561186708254\n",
      "Std Dev Train Recall-Macro score: 0.001744344235633813\n",
      "Std Dev Validation Recall-Macro score: 0.0070561443983079095\n",
      "\n",
      "Mean Train Precision-Macro score: 0.6020318950727404\n",
      "Mean Validation Precision-Macro score: 0.5509299078375789\n",
      "Std Dev Train Precision-Macro score: 0.007452764640657274\n",
      "Std Dev Validation Precision-Macro score: 0.01857242648206825\n"
     ]
    }
   ],
   "source": [
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline_XGB,\n",
    "    X,\n",
    "    y_encoded,\n",
    "    cv=kf,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# F1-Macro\n",
    "train_f1_scores = cv_results['train_f1_macro']\n",
    "val_f1_scores = cv_results['test_f1_macro']\n",
    "print(\"Train F1-Macro scores for each fold:\", train_f1_scores)\n",
    "print(\"Validation F1-Macro scores for each fold:\", val_f1_scores)\n",
    "print(\"Mean Train F1-Macro score:\", train_f1_scores.mean())\n",
    "print(\"Mean Validation F1-Macro score:\", val_f1_scores.mean())\n",
    "print(\"Std Dev Train F1-Macro score:\", train_f1_scores.std())\n",
    "print(\"Std Dev Validation F1-Macro score:\", val_f1_scores.std())\n",
    "\n",
    "# Recall-Macro\n",
    "train_recall_scores = cv_results['train_recall_macro']\n",
    "val_recall_scores = cv_results['test_recall_macro']\n",
    "print(\"\\nMean Train Recall-Macro score:\", train_recall_scores.mean())\n",
    "print(\"Mean Validation Recall-Macro score:\", val_recall_scores.mean())\n",
    "print(\"Std Dev Train Recall-Macro score:\", train_recall_scores.std())\n",
    "print(\"Std Dev Validation Recall-Macro score:\", val_recall_scores.std())\n",
    "\n",
    "# Precision-Macro\n",
    "train_precision_scores = cv_results['train_precision_macro']\n",
    "val_precision_scores = cv_results['test_precision_macro']\n",
    "print(\"\\nMean Train Precision-Macro score:\", train_precision_scores.mean())\n",
    "print(\"Mean Validation Precision-Macro score:\", val_precision_scores.mean())\n",
    "print(\"Std Dev Train Precision-Macro score:\", train_precision_scores.std())\n",
    "print(\"Std Dev Validation Precision-Macro score:\", val_precision_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fourteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.3. Neural Network\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. GridSearch to find the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the GridSearch takes a lot of time, we performed it once and saved the best parameters. That's why the next section is commented out. The same approach will be used for the other GridSearches in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLPClassifier(\n",
    "#     hidden_layer_sizes=(250, 120)\n",
    "#     ,batch_size=500\n",
    "#     ,max_iter=400\n",
    "#     ,random_state=20\n",
    "# )\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'select_k_best__k': list(range(5, 50, 3)),\n",
    "\n",
    "#     'final_model__solver': ['lbfgs', 'sgd', 'adam']\n",
    "#     ,'final_model__learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "#     ,'final_model__learning_rate_init': [0.1, 0.01],\n",
    "# }\n",
    "\n",
    "\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('select_k_best', SelectKBest(score_func=f_classif)),\n",
    "#     ('final_model', model)\n",
    "# ])\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     param_grid,\n",
    "#     cv=kf,\n",
    "#     scoring='f1_macro',\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_search.fit(imp_X, imp_y)\n",
    "\n",
    "# # Access the best pipeline\n",
    "# best_mlp = grid_search.best_params_\n",
    "\n",
    "# print(f'Best params: {best_mlp}')\n",
    "# print(f'Best Score: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SMOTE + SelectKBest + MLPClassifier\n",
    "#pipeline_NN = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', SelectKBest(k=42, score_func=f_classif)),\n",
    "#    ('final_model', MLPClassifier(\n",
    "#        hidden_layer_sizes=(250, 120)\n",
    "#        ,batch_size=500\n",
    "#        ,max_iter=400\n",
    "#        ,random_state=20\n",
    "#        ,learning_rate='constant'\n",
    "#        ,learning_rate_init=0.01\n",
    "#        ,solver='adam'\n",
    "#    ))\n",
    "#])\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_NN,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring='f1_macro',\n",
    "#    return_train_score=True,\n",
    "#    verbose=2\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Train F1-Macro scores for each fold:\", cv_results['train_score'])\n",
    "#print(\"Validation F1-Macro scores for each fold:\", cv_results['test_score'])\n",
    "#print(\"Mean Train F1-Macro score:\", cv_results['train_score'].mean())\n",
    "#print(\"Mean Validation F1-Macro score:\", cv_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the first fold\n",
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    pipeline_NN.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_NN.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline_NN.classes_, yticklabels=pipeline_NN.classes_)\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "#    \n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fifteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.4. Decision Tree\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. Splitting Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_gini = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier())\n",
    "# ])\n",
    "\n",
    "# # Iterate only through the first fold\n",
    "# for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#     # Split the data into training and validation sets for the first fold\n",
    "#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "#     # Fit the pipeline on the training data for the first fold\n",
    "#     pipeline_DT_gini.fit(X_train, y_train)\n",
    "    \n",
    "#     # Extract the trained DecisionTreeClassifier model from the pipeline\n",
    "#     decision_tree_model = pipeline_DT_gini.named_steps['model']\n",
    "    \n",
    "#     # Collect tree metrics\n",
    "#     depth = decision_tree_model.get_depth()  # Depth of the tree\n",
    "#     node_count = decision_tree_model.tree_.node_count  # Total number of nodes in the tree\n",
    "#     leaf_count = decision_tree_model.get_n_leaves()  # Number of leaf nodes in the tree\n",
    "    \n",
    "#     # Print the tree metrics\n",
    "#     print(f\"The tree trained on the first fold has a depth of {depth}.\")\n",
    "#     print(f\"It contains {node_count} total nodes.\")\n",
    "#     print(f\"And it has {leaf_count} leaves\")\n",
    "#     \n",
    "#     # Stop the loop after the first fold\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our criteria will be choosing the model with the highest validation score, always considering overfitting and underfitting. \n",
    "Also, the first criteria that we always consider is the default for that parameter. The objective of this evaluation of parameters is to chose the ones to include in the GridSearch\n",
    "\n",
    "__1. criterion = 'gini' or criterion = 'entropy'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_entropy = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy'))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['Gini','Entropy'])\n",
    "# show_results(df,pipeline_DT_gini, pipeline_DT_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__criterion = 'entropy'__ has a higher validation score, so we will chose 'entropy'\n",
    "\n",
    "__2. splitter = 'best' or splitter = 'random'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_random = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', splitter = 'random'))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['best','random'])\n",
    "# show_results(df,pipeline_DT_entropy, pipeline_DT_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__splitter = 'best'__ has a higher validation score, so we will chose 'best'\n",
    "\n",
    "__3. max_depth = 'none' or max_depth = 20 or max_depth = 30 or max_depth = 40__\n",
    "\n",
    "We choose these values because we already know our current decision tree has a depth of 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_depth20 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy',max_depth = 20))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_depth30 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy',max_depth = 30))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_depth40 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy',max_depth = 40))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['full','depth20','depth30','depth40'])\n",
    "# show_results(df,pipeline_DT_entropy, pipeline_DT_depth20, pipeline_DT_depth30, pipeline_DT_depth40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__max_depth = 20__ has a higher validation score, however it has a low train score comparing with the others. Lets test values for max_depth between 1 and 48 in order to obtain the best for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_max_depth_vs_f1(X, y):\n",
    "#     # List the max_depth values to be tested (from 1 to 48, excluding 'none')\n",
    "#     depths = list(range(1, 49))\n",
    "#     \n",
    "#     train_scores = []\n",
    "#     val_scores = []\n",
    "#\n",
    "#     for depth in depths:\n",
    "#         pipeline_DT_depths = Pipeline(steps=[\n",
    "#            *preproc_steps,\n",
    "#            ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = depth))\n",
    "#         ])\n",
    "#     \n",
    "#         # Calculate the F1 scores for training and validation\n",
    "#         avg_train_f1, avg_val_f1 = avg_score(pipeline_DT_depths, X, y)\n",
    "#     \n",
    "#         # Add the F1 scores to the list, accessing only the average value\n",
    "#         train_scores.append(avg_train_f1)  # Extract the numeric value\n",
    "#         val_scores.append(avg_val_f1)      # Extract the numeric value\n",
    "#   \n",
    "#     # Plot the results\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(depths, train_scores, label='Train F1 Score', marker='o', linestyle='-', color='blue')\n",
    "#     plt.plot(depths, val_scores, label='Validation F1 Score', marker='o', linestyle='--', color='red')\n",
    "#     plt.title('F1 Score vs Max Depth of Decision Tree')\n",
    "#     plt.xlabel('Max Depth')\n",
    "#     plt.ylabel('F1 Score (Macro)')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Call the function to plot the graph\n",
    "# plot_max_depth_vs_f1(X, pd.DataFrame(y_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model with max_depth = 14 is the one with the highest validation score. However that depth can lead to overfitting. To obtain a good trade off betwenn the validation score and the training score in order to have a high validation score with less overfitting we will chose for GridSearch __max_depth = 12 , max_depth = 13 and max_depth = 14__\n",
    "\n",
    "__4. min_samples_split = 2 or min_samples_split = 10 or min_samples_split = 50 or min_samples_split = 100__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_depth12 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_min10 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_split = 10))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_min50 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#    ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_split = 50))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_min100 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_split = 100))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['Original','dt_min10','dt_min50','dt_min100'])\n",
    "# show_results(df, pipeline_DT_depth12, pipeline_DT_min10, pipeline_DT_min50, pipeline_DT_min100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with min_samples_split = 50 has the highest validation score, followed by min_samples_split = 2, so let´s include both in the GridSearch.\n",
    "\n",
    "__5. min_samples_leaf = 1 or min_samples_leaf = 10 or min_samples_leaf = 50 or min_samples_leaf = 100__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_sam10 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_leaf = 10))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_sam50 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_leaf = 50))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_sam100 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_samples_leaf = 100))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['Original','dt_min_sam10','dt_min_sam50','dt_min_sam100'])\n",
    "# show_results(df,pipeline_DT_depth12, pipeline_DT_sam10, pipeline_DT_sam50, pipeline_DT_sam100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them have similar validation scores, but the default value has a higher probability of overfitting. We will chose __min_samples_leaf = 10 and min_samples_leaf = 100__ for the GridSearch.\n",
    "\n",
    "__6. max_features = 'none' or max_features = 2 or max_features = 0.5 or max_features = 'sqrt' or max_features = 'log2'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_int = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_features = 2))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_float = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_features = 0.5))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_sqrt = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_features = 'sqrt'))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_log2 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_features = 'log2'))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['None (Original)','2','0.5','Sqrt','Log2'])\n",
    "# show_results(df,pipeline_DT_depth12, pipeline_DT_int, pipeline_DT_float, pipeline_DT_sqrt, pipeline_DT_log2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will chose __max_features = 'none' and max_features = 0.5__ because they have high validation scores.\n",
    "\n",
    "__7. max_leaf_nodes = 'none' or max_leaf_nodes = 10 or max_leaf_nodes = 20 or max_leaf_nodes = 30 or max_leaf_nodes = 40__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_maxleaf10 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_leaf_nodes = 10))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_maxleaf20 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_leaf_nodes = 20))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_maxleaf30 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_leaf_nodes = 30))\n",
    "# ])\n",
    "\n",
    "# pipeline_DT_maxleaf40 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, max_leaf_nodes = 40))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['None (Original)','dt_maxleaf10','dt_maxleaf20','dt_maxleaf30','dt_maxleaf40'])\n",
    "# show_results(df,pipeline_DT_depth12, pipeline_DT_maxleaf10, pipeline_DT_maxleaf20, pipeline_DT_maxleaf30, pipeline_DT_maxleaf40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will chose __max_leaf_nodes = 'none'__ (the default value) because it has the highest validation score.\n",
    "\n",
    "__8. min_impurity_decrease=0. or min_impurity_decrease=0.02__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_impurity02 = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier(criterion = 'entropy', max_depth = 12, min_impurity_decrease=0.02))\n",
    "# ])\n",
    "\n",
    "# df = pd.DataFrame(columns = ['Train','Val'], index = ['Original','dt_impurity02'])\n",
    "# show_results(df,pipeline_DT_depth12, pipeline_DT_impurity02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose min_impurity_decrease =0. (the default value) because it has the highest validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2. GridSearch to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_DT_GridSearch = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('model', DecisionTreeClassifier())\n",
    "# ])\n",
    "\n",
    "# parameter_space = {\n",
    "#     'model__criterion': ['entropy'],\n",
    "#     'model__max_depth': [12, 13, 14],\n",
    "#     'model__min_samples_split': [2, 50],\n",
    "#     'model__min_samples_leaf': [10, 100],\n",
    "#     'model__max_features': [0.5, None],\n",
    "# }\n",
    "\n",
    "# # Set up the GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=pipeline_DT_GridSearch,  # The pipeline that contains the model and preprocessing\n",
    "#     param_grid=parameter_space,  # The hyperparameters you want to tune\n",
    "#     cv=kf,  # Cross-validation set up earlier\n",
    "#     scoring='f1_macro',  # Evaluation metric\n",
    "#     return_train_score=True,  # Also return training scores\n",
    "#     verbose=2,  # Display progress\n",
    "#     n_jobs=-1  # Use all available cores to speed up\n",
    "# )\n",
    "\n",
    "# # Run the GridSearchCV\n",
    "# gsCV = grid_search.fit(imp_X, imp_y)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# print(\"Best Parameters:\", gsCV.best_params_)\n",
    "# print(\"Best Score:\", gsCV.best_score_)\n",
    "\n",
    "# OUTPUT\n",
    "# Best Parameters: {'model__criterion': 'entropy', 'model__max_depth': 13, 'model__max_features': None, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
    "# Best Score: 0.34637161099074404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with DecisionTreeClassifier\n",
    "#pipeline_DT = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('model', DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10))\n",
    "#])\n",
    "\n",
    "## Scoring Metrics\n",
    "#scoring = {\n",
    "#    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "#    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "#    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "#}\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_DT,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## F1-Macro\n",
    "#train_f1_scores = cv_results['train_f1_macro']\n",
    "#val_f1_scores = cv_results['test_f1_macro']\n",
    "#print(\"Train F1-Macro scores for each fold:\", train_f1_scores)\n",
    "#print(\"Validation F1-Macro scores for each fold:\", val_f1_scores)\n",
    "#print(\"Mean Train F1-Macro score:\", round(train_f1_scores.mean(),4))\n",
    "#print(\"Mean Validation F1-Macro score:\", round(val_f1_scores.mean(),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Pipeline with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SMOTE + SelectKBest + DecisionTreeClassifier\n",
    "#pipeline_DT_SMOTE = ImbPipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('smote', SMOTE(random_state=20, k_neighbors=3)),\n",
    "#    ('model', DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10))\n",
    "#])\n",
    "\n",
    "## f1 score\n",
    "#scoring = {'f1_macro': make_scorer(f1_score, average='macro')}\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results_smote = cross_validate(\n",
    "#    pipeline_DT_SMOTE,\n",
    "#    X,  \n",
    "#    y_encoded,  \n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Mean Train F1-Macro with SMOTE:\", round(cv_results_smote['train_f1_macro'].mean(), 4))\n",
    "#print(\"Mean Validation F1-Macro with SMOTE:\", round(cv_results_smote['test_f1_macro'].mean(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.4. 1vsALL - Decision Tree with smote and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the general pipeline with OneVsRestClassifier\n",
    "#pipeline_1vsALL = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('classifier', OneVsRestClassifier(DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "## Evaluate with cross-validation (using F1 macro)\n",
    "#f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "#scores = cross_val_score(pipeline_1vsALL, X, y_encoded, cv=kf, scoring=f1_macro_scorer)\n",
    "\n",
    "#print(f\"F1 Macro Scores per Fold: {scores}\")\n",
    "#print(f\"Average F1 Macro: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate predictions for each fold\n",
    "#y_pred = cross_val_predict(pipeline_1vsALL, X, y_encoded, cv=kf)\n",
    "\n",
    "## Generate the classification report\n",
    "#report = classification_report(y_encoded, y_pred, target_names=sorted(y.unique()))\n",
    "\n",
    "## Display the report\n",
    "#print(\"Classification Report:\")\n",
    "#print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.5. Bagging of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with BaggingClassifier\n",
    "#pipeline_bagging = Pipeline(steps=[ \n",
    "#    *preproc_steps,\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "#df = pd.DataFrame(columns = ['Train','Val'], index = ['Decision Tree','with SMOTE','1vsALL','Bagging'])\n",
    "#show_results(df,pipeline_DT, pipeline_DT_SMOTE, pipeline_1vsALL, pipeline_bagging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6. Feature Importance - deciding number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding the number of features to mantain - with SelectKBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SelectKBest + BaggingClassifier\n",
    "#pipeline_DT_GridSearch = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', SelectKBest(score_func=f_classif)),\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "#parameter_space = {\n",
    "#    'select_k_best__k': list(range(30, 71, 3)),\n",
    "#}\n",
    "\n",
    "## Set up the GridSearchCV\n",
    "#grid_search = GridSearchCV(\n",
    "#    estimator=pipeline_DT_GridSearch,  # The pipeline that contains the model and preprocessing\n",
    "#    param_grid=parameter_space,  # The hyperparameters you want to tune\n",
    "#    cv=kf,  # Cross-validation set up earlier\n",
    "#    scoring='f1_macro',  # Evaluation metric\n",
    "#    return_train_score=True,  # Also return training scores\n",
    "#    verbose=2,  # Display progress\n",
    "#    n_jobs=-1  # Use all available cores to speed up\n",
    "#)\n",
    "\n",
    "## Run the GridSearchCV\n",
    "#gsCV = grid_search.fit(imp_X, imp_y)\n",
    "\n",
    "## Get the best parameters and score\n",
    "#print(\"Best Parameters:\", gsCV.best_params_)\n",
    "#print(\"Best Score:\", gsCV.best_score_)\n",
    "\n",
    "## OUTPUT\n",
    "## Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
    "## Best Parameters: {'select_k_best__k': 57}\n",
    "## Best Score: 0.34920766156521943\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding the number of features to mantain - with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SMOTE + SelectKBest + Random Forest\n",
    "#pipeline_DT_fs3 = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('feature_selector', XGBFeatureSelector(num_features=32)),  # Feature Selection\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "#feature_intervals = range(30, 71, 3)\n",
    "\n",
    "#results_DT = evaluate_feature_intervals(pipeline_DT_fs3, imp_X, imp_y, feature_intervals, scoring='f1_macro', cv=2)\n",
    "\n",
    "#results_DT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding the number of features to mantain - with DecisionTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the parameters and thresholds for feature selection\n",
    "#tresholds = [0.025, 0.020, 0.015, 0.010, 0.005, 0.001, 0]\n",
    "#number_of_feat = []\n",
    "#f1_train = []\n",
    "#f1_val = []\n",
    "\n",
    "#y_new = pd.DataFrame(imp_y)\n",
    "\n",
    "## Initializing the list to store results from each fold\n",
    "#for tresh in tresholds:\n",
    "#    # Creating the structure of lists to store results for each fold\n",
    "#    fold_train_f1 = []\n",
    "#    fold_val_f1 = []\n",
    "    \n",
    "#    # Creating an object to store feature importances\n",
    "#    gini_importance_list = []\n",
    "#    entropy_importance_list = []\n",
    "\n",
    "#    # StratifiedKFold to split data into train and validation sets\n",
    "#    for train_index, val_index in kf.split(imp_X, y_new):\n",
    "#        # Splitting data into train and validation sets\n",
    "#        X_train_fold, X_val_fold = imp_X.iloc[train_index], imp_X.iloc[val_index]\n",
    "#        y_train_fold, y_val_fold = y_new.iloc[train_index], y_new.iloc[val_index]\n",
    "\n",
    "#        # Defining the classification model within the pipeline (with preprocessing)\n",
    "#        model_gini = Pipeline(steps=[\n",
    "#            *preproc_steps,\n",
    "#            ('model', BaggingClassifier(\n",
    "#                base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#                max_depth=13, \n",
    "#                min_samples_leaf=10)))\n",
    "#        ])\n",
    "\n",
    "#        # Training the model using Gini (transformation will be done within the Pipeline)\n",
    "#        model_gini.fit(X_train_fold, y_train_fold)\n",
    "#        gini_importance = np.mean([tree.feature_importances_ for tree in model_gini.named_steps['model'].estimators_], axis=0)\n",
    "\n",
    "#        # Training the model using Entropy\n",
    "#        model_entropy = Pipeline(steps=[\n",
    "#            *preproc_steps,\n",
    "#            ('model', BaggingClassifier(\n",
    "#                base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#                criterion = 'entropy',\n",
    "#                max_depth=13, \n",
    "#                min_samples_leaf=10)))\n",
    "#        ])\n",
    "\n",
    "#        model_entropy.fit(X_train_fold, y_train_fold)\n",
    "#        entropy_importance = np.mean([tree.feature_importances_ for tree in model_entropy.named_steps['model'].estimators_], axis=0)\n",
    "\n",
    "#        # Storing the importances\n",
    "#        gini_importance_list.append(gini_importance)\n",
    "#        entropy_importance_list.append(entropy_importance)\n",
    "\n",
    "#        # Calculating predictions and F1 score for the training set\n",
    "#        train_predictions = model_gini.predict(X_train_fold)\n",
    "#        train_f1 = f1_score(y_train_fold, train_predictions, average='macro')\n",
    "#        fold_train_f1.append(train_f1)\n",
    "\n",
    "#        # Calculating predictions and F1 score for the validation set\n",
    "#        val_predictions = model_gini.predict(X_val_fold)\n",
    "#        val_f1 = f1_score(y_val_fold, val_predictions, average='macro')\n",
    "#        fold_val_f1.append(val_f1)\n",
    "    \n",
    "#    # Calculating the average of feature importances and scores\n",
    "#    avg_train_f1 = sum(fold_train_f1) / len(fold_train_f1)\n",
    "#    avg_val_f1 = sum(fold_val_f1) / len(fold_val_f1)\n",
    "    \n",
    "#    # Calculating the average feature importances\n",
    "#    avg_gini_importance = sum(gini_importance_list) / len(gini_importance_list)\n",
    "#    avg_entropy_importance = sum(entropy_importance_list) / len(entropy_importance_list)\n",
    "\n",
    "#    # Filtering features based on the threshold\n",
    "#    selected_features = [X.columns[i] for i in range(len(X.columns)) if avg_gini_importance[i] > tresh or avg_entropy_importance[i] > tresh]\n",
    "\n",
    "#    # Storing results\n",
    "#    number_of_feat.append(len(selected_features))\n",
    "#    f1_train.append(avg_train_f1)\n",
    "#    f1_val.append(avg_val_f1)\n",
    "\n",
    "## Final results\n",
    "#feature_selection_results = pd.DataFrame({\n",
    "#    'Treshold': tresholds,\n",
    "#    'Number of Features': number_of_feat,\n",
    "#    'Train F1': f1_train,\n",
    "#    'Val F1': f1_val\n",
    "#})\n",
    "\n",
    "## Displaying the results\n",
    "#print(feature_selection_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.7. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SelectKBest + BaggingClassifier\n",
    "#pipeline_DT_fs1 = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', SelectKBest(k=57 ,score_func=f_classif)),  # Feature Selection\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "## Pipeline with DT_FeatureSelector + BaggingClassifier\n",
    "#pipeline_DT_fs2 = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('feature_selector', DT_FeatureSelector(gini_threshold=0.005, entropy_threshold=0.005)),  # Feature Selection\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "## Pipeline with XGBFeatureSelector + BaggingClassifier\n",
    "#pipeline_DT_fs3 = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('feature_selector', XGBFeatureSelector(num_features=39)),  # Feature Selection\n",
    "#    ('model', BaggingClassifier(\n",
    "#    base_estimator=DecisionTreeClassifier(  # model with the best parameters found in GridSearch\n",
    "#        criterion='entropy',\n",
    "#        max_depth=13, \n",
    "#        min_samples_leaf=10)))\n",
    "#])\n",
    "\n",
    "#df = pd.DataFrame(columns = ['Train','Val'], index = ['Without FS','FS-SelectKBest','FS-DT', 'FS-XGB'])\n",
    "#show_results(df,pipeline_bagging, pipeline_DT_fs1, pipeline_DT_fs2, pipeline_DT_fs3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_DT_Best = # depende do output da anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.8. Predict on the whole DataSet with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scoring Metrics\n",
    "#scoring = {\n",
    "#    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "#    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "#    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "#}\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_DT_Best,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True,\n",
    "#    n_jobs=7\n",
    "#)\n",
    "\n",
    "## F1-Macro\n",
    "#train_f1_scores = cv_results['train_f1_macro']\n",
    "#val_f1_scores = cv_results['test_f1_macro']\n",
    "#print(f\"Train F1-Macro Scores: {train_f1_scores}\")\n",
    "#print(f\"Validation F1-Macro Scores: {val_f1_scores}\")\n",
    "#print(f\"Mean Train F1-Macro: {train_f1_scores.mean():.4f}\")\n",
    "#print(f\"Mean Validation F1-Macro: {val_f1_scores.mean():.4f}\")\n",
    "#print(f\"Std Dev of Validation F1-Macro: {val_f1_scores.std():.4f}\")\n",
    "#print(f\"Mean Validation Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "#print(f\"Mean Validation Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.9. Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    pipeline_DT_Best.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_DT_Best.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_encoded), yticklabels=np.unique(y_encoded))\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "\n",
    "#    # Compute and print the classification report\n",
    "#    class_report = classification_report(y_val, y_val_pred, digits=4)\n",
    "#    print(\"\\nClassification Report for a Single Fold:\")\n",
    "#    print(class_report)\n",
    "#    \n",
    "#    # Stop after the first fold\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sixteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.5. Logistic Regression\n",
    "</a> \n",
    "</d>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. GridSearch to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with LogisticRegression\n",
    "#pipeline_LR_GridSearch = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('model', LogisticRegression(\n",
    "#            random_state=42,\n",
    "#            max_iter=1000))\n",
    "#])\n",
    "\n",
    "## parameter_space_LR = [\n",
    "##     {\n",
    "##         # Regularization strength\n",
    "##         'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "##         # Penalty types\n",
    "##         'model__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "##         # Solvers for Logistic Regression\n",
    "##         'model__solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg'],\n",
    "##         # ElasticNet mixing parameter (if 'penalty' is 'elasticnet')\n",
    "##         'model__l1_ratio': [0.2, 0.5, 0.8, None],\n",
    "##     }\n",
    "## ]\n",
    "\n",
    "## Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
    "## Best Parameters: {'model__C': 10, 'model__l1_ratio': 0.2, 'model__penalty': 'l1', 'model__solver': 'liblinear'} #penalty is ignored since the best penalty is not 'elasticnet'\n",
    "## Best Score: 0.40897484704172876\n",
    "## F1-score weighted:  0.72336836598011\n",
    "## F1-score macro:  0.39291706072616295\n",
    "\n",
    "#parameter_space_LR = [\n",
    "#    {\n",
    "#        # Regularization strength\n",
    "#        'model__C': [10],\n",
    "#        # Penalty types\n",
    "#        'model__penalty': ['l1'],\n",
    "#        # Solvers for Logistic Regression\n",
    "#        'model__solver': ['liblinear']\n",
    "#    }\n",
    "#]\n",
    "\n",
    "## Wrap the pipeline in GridSearchCV\n",
    "#grid_search_LR = GridSearchCV(\n",
    "#    estimator=pipeline_LR_GridSearch,\n",
    "#    param_grid=parameter_space_LR,\n",
    "#    scoring='f1_macro',\n",
    "#    cv=kf,  # 5-fold cross-validation\n",
    "#    verbose=2,\n",
    "#    n_jobs=7  # Use all available CPU cores\n",
    "#)\n",
    "\n",
    "## Run the GridSearchCV\n",
    "#gsLRCV = grid_search_LR.fit(imp_X, imp_y)\n",
    "#best_params_LR = gsLRCV.best_params_\n",
    "\n",
    "## Get the best parameters and score\n",
    "#print(\"Best Parameters:\", best_params_LR)\n",
    "#print(\"Best Score:\", gsLRCV.best_score_)\n",
    "\n",
    "#best_LR = gsLRCV.best_estimator_\n",
    "\n",
    "#preds_LR = best_LR.predict(X)\n",
    "\n",
    "#print(\"F1-score weighted: \", f1_score(y_encoded, preds_LR, average= 'weighted'))\n",
    "#print(\"F1-score macro: \",f1_score(y_encoded, preds_LR, average= 'macro'))\n",
    "\n",
    "\n",
    "## # OUTPUT\n",
    "##Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
    "##Best Parameters: {'model__C': 10, 'model__l1_ratio': 0.2, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
    "##Best Score: 0.40897484704172876\n",
    "##F1-score weighted:  0.72336836598011\n",
    "##F1-score macro:  0.39291706072616295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best model penalty is not 'elasticnet', l1_ration is not relevant so we can remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Feature Selection with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust the pipeline to use LogisticRegression\n",
    "#pipeline_LR_KB = Pipeline(steps=[    \n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', SelectKBest(score_func=f_classif)),  # Feature selection\n",
    "#    ('model', LogisticRegression(\n",
    "#        random_state=42,\n",
    "#        max_iter=1000,\n",
    "#        C=best_params_LR['model__C'],\n",
    "#        l1_ratio=best_params_LR['model__l1_ratio'],\n",
    "#        penalty=best_params_LR['model__penalty'],\n",
    "#        solver=best_params_LR['model__solver']))\n",
    "#])\n",
    "\n",
    "## # Define the parameter grid for feature selection\n",
    "#parameter_space_FS = {\n",
    "#    'select_k_best__k': list(range(40, 74))\n",
    "#}\n",
    "\n",
    "## Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
    "## Best Parameters: {'select_k_best__k': 73}\n",
    "## Best Score: 0.41358298612532723\n",
    "\n",
    "## # Define the parameter grid for feature selection\n",
    "## parameter_space_FS = {\n",
    "##     'select_k_best__k': [67]  # Best number is 67\n",
    "## }\n",
    "\n",
    "## Set up GridSearchCV\n",
    "#grid_search = GridSearchCV(\n",
    "#    estimator=pipeline_LR_KB,  # The pipeline that contains the model and preprocessing\n",
    "#    param_grid=parameter_space_FS,  # The hyperparameters to tune\n",
    "#    cv=kf,  # Cross-validation set up earlier\n",
    "#    scoring='f1_macro',  # Evaluation metric\n",
    "#    return_train_score=True,  # Also return training scores\n",
    "#    verbose=2,  # Display progress\n",
    "#    n_jobs=7  # Use all available cores to speed up\n",
    "#)\n",
    "\n",
    "## Run the GridSearchCV\n",
    "#gsCVLRKB = grid_search.fit(imp_X, imp_y)\n",
    "\n",
    "#best_k = gsCVLRKB.best_params_['select_k_best__k']\n",
    "\n",
    "## Get the best parameters and score\n",
    "#print(\"Best Parameters:\", gsCVLRKB.best_params_)\n",
    "#print(\"Best Score:\", gsCVLRKB.best_score_)\n",
    "\n",
    "\n",
    "## # OUTPUT\n",
    "##Fitting 5 folds for each of 34 candidates, totalling 170 fits\n",
    "##Best Parameters: {'select_k_best__k': 67}\n",
    "##Best Score: 0.39661791227581744\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the best model\n",
    "#best_LR_KB = gsCVLRKB.best_estimator_\n",
    "\n",
    "## Make predictions and evaluate the model\n",
    "#preds = best_LR_KB.predict(X)\n",
    "#print(\"F1-score weighted: \", f1_score(y_encoded, preds, average='weighted'))\n",
    "#print(\"F1-score macro: \", f1_score(y_encoded, preds, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Predict on the whole DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_LR_XGB_FULL = Pipeline(steps=[\n",
    "#     *preproc_steps,\n",
    "#     ('select_k_best', XGBFeatureSelector(num_features=68)),  \n",
    "#     ('model', LogisticRegression(\n",
    "#             random_state=42,\n",
    "#             max_iter=1000,\n",
    "#             C=10,\n",
    "#             penalty='l1',\n",
    "#             solver='liblinear'))\n",
    "# ])\n",
    "\n",
    "# # Scoring Metrics \n",
    "# scoring = {\n",
    "#    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "#    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "#    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "# }\n",
    "\n",
    "# # Cross Validation\n",
    "# cv_results_LR_KB = cross_validate(\n",
    "#    pipeline_LR_XGB_FULL,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True,\n",
    "#    n_jobs=7\n",
    "# )\n",
    "\n",
    "# # F1-Macro\n",
    "# train_f1_scores_LR_KB = cv_results_LR_KB['train_f1_macro']\n",
    "# val_f1_scores_LR_KB = cv_results_LR_KB['test_f1_macro']\n",
    "# print(f\"Train F1-Macro Scores: {train_f1_scores_LR_KB}\")\n",
    "# print(f\"Validation F1-Macro Scores: {val_f1_scores_LR_KB}\")\n",
    "# print(f\"Mean Train F1-Macro: {train_f1_scores_LR_KB.mean():.4f}\")\n",
    "# print(f\"Mean Validation F1-Macro: {val_f1_scores_LR_KB.mean():.4f}\")\n",
    "# print(f\"Std Dev of Validation F1-Macro: {val_f1_scores_LR_KB.std():.4f}\")\n",
    "# print(f\"Mean Validation Recall-Macro: {cv_results_LR_KB['test_recall_macro'].mean():.4f}\")\n",
    "# print(f\"Mean Validation Precision-Macro: {cv_results_LR_KB['test_precision_macro'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4. Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    pipeline_LR_KB_FULL.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_LR_KB_FULL.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_encoded), yticklabels=np.unique(y_encoded))\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "\n",
    "#    # Compute and print the classification report\n",
    "#    class_report = classification_report(y_val, y_val_pred, digits=4)\n",
    "#    print(\"\\nClassification Report for a Single Fold:\")\n",
    "#    print(class_report)\n",
    "#    \n",
    "#    # Stop after the first fold\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.5 Feature Selection with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the XGBoost-based feature selector\n",
    "#xgb_feature_selector = XGBFeatureSelector()  # You can tune `num_features`\n",
    "\n",
    "## Create the pipeline\n",
    "#pipeline_LR_XGB = Pipeline(steps=[\n",
    "#    *preproc_steps,  # Existing preprocessing steps\n",
    "#    ('xgb_feature_selector', xgb_feature_selector),  # Feature selection using XGBoost\n",
    "#    ('model', LogisticRegression(\n",
    "#        random_state=42,\n",
    "#        max_iter=1000,\n",
    "#        C=best_params_LR['model__C'],\n",
    "#        l1_ratio=best_params_LR['model__l1_ratio'],\n",
    "#        penalty=best_params_LR['model__penalty'],\n",
    "#        solver=best_params_LR['model__solver']))\n",
    "#])\n",
    "\n",
    "## Define the parameter grid for feature selection\n",
    "#parameter_space_FS = {\n",
    "#    'xgb_feature_selector__num_features': list(range(45, 71)),  # Number of features to select\n",
    "#}\n",
    "\n",
    "## Set up GridSearchCV\n",
    "#grid_search = GridSearchCV(\n",
    "#    estimator=pipeline_LR_XGB,\n",
    "#    param_grid=parameter_space_FS,\n",
    "#    cv=kf,\n",
    "#    scoring='f1_macro',\n",
    "#    return_train_score=True,\n",
    "#    verbose=2,\n",
    "#    n_jobs=7\n",
    "#)\n",
    "\n",
    "## Run the GridSearchCV\n",
    "#gsCVLRXGB = grid_search.fit(imp_X, imp_y)\n",
    "#best_XGB = gsCVLRXGB.best_params_['xgb_feature_selector__num_features']\n",
    "\n",
    "## Get the best parameters and score\n",
    "#print(\"Best Parameters:\", gsCVLRXGB.best_params_)\n",
    "#print(\"Best Score:\", gsCVLRXGB.best_score_)\n",
    "\n",
    "\n",
    "## #OUTPUT\n",
    "##Fitting 5 folds for each of 26 candidates, totalling 130 fits\n",
    "##Best Parameters: {'xgb_feature_selector__num_features': 68}\n",
    "##Best Score: 0.39213992061634484\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the best model\n",
    "#best_LR_XGB = gsCVLRXGB.best_estimator_\n",
    "\n",
    "## Make predictions and evaluate the model\n",
    "#preds = best_LR_XGB.predict(X)\n",
    "#print(\"F1-score weighted: \", f1_score(y_encoded, preds, average='weighted'))\n",
    "#print(\"F1-score macro: \", f1_score(y_encoded, preds, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.6 Predict on the whole DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SelectKBest + LogisticRegression\n",
    "#pipeline_LR_XGB_FULL = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', XGBFeatureSelector(num_features=best_XGB)),  # Add the best k from GridSearchCV\n",
    "#    ('model', LogisticRegression(\n",
    "#            random_state=42,\n",
    "#            max_iter=1000,\n",
    "#            C=best_params_LR['model__C'],\n",
    "#            l1_ratio=best_params_LR['model__l1_ratio'],\n",
    "#            penalty=best_params_LR['model__penalty'],\n",
    "#            solver=best_params_LR['model__solver']))\n",
    "#])\n",
    "\n",
    "## Scoring Metrics\n",
    "#scoring = {\n",
    "#    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "#    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "#    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "#}\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_LR_XGB_FULL,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True,\n",
    "#    n_jobs=7\n",
    "#)\n",
    "\n",
    "## F1-Macro\n",
    "#train_f1_scores = cv_results['train_f1_macro']\n",
    "#val_f1_scores = cv_results['test_f1_macro']\n",
    "#print(f\"Train F1-Macro Scores: {train_f1_scores}\")\n",
    "#print(f\"Validation F1-Macro Scores: {val_f1_scores}\")\n",
    "#print(f\"Mean Train F1-Macro: {train_f1_scores.mean():.4f}\")\n",
    "#print(f\"Mean Validation F1-Macro: {val_f1_scores.mean():.4f}\")\n",
    "#print(f\"Std Dev of Validation F1-Macro: {val_f1_scores.std():.4f}\")\n",
    "#print(f\"Mean Validation Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "#print(f\"Mean Validation Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.7 Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    pipeline_LR_XGB_FULL.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_LR_XGB_FULL.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_encoded), yticklabels=np.unique(y_encoded))\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "\n",
    "#    # Compute and print the classification report\n",
    "#    class_report = classification_report(y_val, y_val_pred, digits=4)\n",
    "#    print(\"\\nClassification Report for a Single Fold:\")\n",
    "#    print(class_report)\n",
    "#    \n",
    "#    # Stop after the first fold\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection with SelectKBest works better than with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"seventeen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.6. Random Forest\n",
    "</a> \n",
    "</d> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample 40000 random samples from the data for imputation\n",
    "#imp_X = X.copy().reset_index(drop=True).sample(40000, random_state=20)\n",
    "#imp_y = y_encoded[imp_X.index.values]\n",
    "\n",
    "#int64_columns = imp_X.select_dtypes(include='Int64').columns\n",
    "#imp_X[int64_columns] = imp_X[int64_columns].astype(float)\n",
    "\n",
    "#imp_X = imp_X.replace({pd.NA: np.nan})\n",
    "#X = X.replace({pd.NA: np.nan})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1. Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "#randomForest = RandomForestClassifier(random_state=20)\n",
    "\n",
    "#pipeline = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('rf_model', randomForest)\n",
    "#])\n",
    "\n",
    "## f1 score\n",
    "#scoring = {'f1_macro': make_scorer(f1_score, average='macro')}\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline,\n",
    "#    imp_X,\n",
    "#    imp_y,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Train F1-Macro:\", round(cv_results['train_f1_macro'].mean(), 4))\n",
    "#print(\"Validation F1-Macro:\", round(cv_results['test_f1_macro'].mean(), 4))\n",
    "\n",
    "##Outputs\n",
    "##Train F1-Macro: 1.0\n",
    "##Validation F1-Macro: 0.3411\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2. Pipeline with SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the pipeline\n",
    "#test_pipe = Pipeline([*preproc_steps])\n",
    "\n",
    "## Fit the pipeline and transform the data\n",
    "#test_pipe.fit(imp_X, imp_y)\n",
    "\n",
    "#X_transfor = test_pipe.transform(imp_X)\n",
    "\n",
    "#print(X_transfor.isna().sum().sum())\n",
    "\n",
    "##Outputs\n",
    "##0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USAR PARA TIRAR O ERRO DO SMOTE\n",
    "# Filtrar classes pequenas\n",
    "#class_counts = Counter(imp_y)\n",
    "#valid_classes = [cls for cls, count in class_counts.items() if count > 5]\n",
    "\n",
    "#mask = np.isin(imp_y, valid_classes)\n",
    "#filtered_X = imp_X[mask]\n",
    "#filtered_y = imp_y[mask]\n",
    "\n",
    "#print(f\"Valid classes after filtering: {valid_classes}\")\n",
    "#print(f\"Number of samples after filtering: {len(filtered_y)}\")\n",
    "#### USAR PARA TIRAR O ERRO DO SMOTE\n",
    "\n",
    "## SMOTE\n",
    "#smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "\n",
    "## Pipeline com SMOTE + Random Forest\n",
    "#pipeline_smote = ImbPipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('smote', smote),\n",
    "#    ('rf_model', randomForest)\n",
    "#])\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results_smote = cross_validate(\n",
    "#    pipeline_smote,\n",
    "#    filtered_X,\n",
    "#    filtered_y,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Mean Train F1-Macro with SMOTE:\", round(cv_results_smote['train_f1_macro'].mean(), 4))\n",
    "#print(\"Mean Validation F1-Macro with SMOTE:\", round(cv_results_smote['test_f1_macro'].mean(), 4))\n",
    "\n",
    "##Outputs\n",
    "##Valid classes after filtering: [2.0, 3.0, 1.0, 4.0, 0.0, 5.0, 7.0, 6.0]\n",
    "##Number of samples after filtering: 40000\n",
    "##Mean Train F1-Macro with SMOTE: 1.0\n",
    "##Mean Validation F1-Macro with SMOTE: 0.3878\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.3. Hyperparameter Tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for RandomizedSearchCV\n",
    "# param_dist = {\n",
    "#     'rf_model__n_estimators': [100, 200, 300],\n",
    "#     'rf_model__max_depth': [10, 20, None],\n",
    "#     'rf_model__min_samples_split': [2, 5, 10],\n",
    "#     'rf_model__min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=pipeline_smote,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=3,\n",
    "#     cv=StratifiedKFold(n_splits=2, shuffle=True, random_state=20),\n",
    "#     scoring='f1_macro',\n",
    "#     verbose=2,\n",
    "#     n_jobs=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# random_search.fit(filtered_X, filtered_y)\n",
    "\n",
    "# Results\n",
    "# print(\"Best parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.4.1 Feature Selection with SelectKBest using Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SelectKBest + Random Forest\n",
    "#pipeline_fs = ImbPipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('select_k_best', SelectKBest(k=30, score_func=f_classif)),\n",
    "#    ('rf_model', RandomForestClassifier(\n",
    "#        n_estimators=100,\n",
    "#        max_depth=10,\n",
    "#        min_samples_split=2,\n",
    "#        min_samples_leaf=1,\n",
    "#        random_state=20 \n",
    "#    ))\n",
    "#])\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_fs,\n",
    "#    filtered_X,\n",
    "#    filtered_y,\n",
    "#    cv=kf,\n",
    "#    scoring='f1_macro',\n",
    "#    return_train_score=True,\n",
    "#    verbose=2,\n",
    "#    n_jobs=2\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Train F1-Macro scores for each fold:\", cv_results['train_score'])\n",
    "#print(\"Validation F1-Macro scores for each fold:\", cv_results['test_score'])\n",
    "#print(\"Mean Train F1-Macro score:\", cv_results['train_score'].mean())\n",
    "#print(\"Mean Validation F1-Macro score:\", cv_results['test_score'].mean())\n",
    "\n",
    "##Outputs\n",
    "##Train F1-Macro scores for each fold: [0.41202632 0.47543542]\n",
    "##Validation F1-Macro scores for each fold: [0.33342228 0.32583513]\n",
    "##Mean Train F1-Macro score: 0.443730873285626\n",
    "##Mean Validation F1-Macro score: 0.32962870395996186\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.4.2 Feature Selection with SelectKBest and SMOTE using Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with SMOTE + SelectKBest + Random Forest\n",
    "#pipeline_fs_smote = ImbPipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('smote', smote),\n",
    "#    ('select_k_best', SelectKBest(k=30, score_func=f_classif)),\n",
    "#    ('rf_model', RandomForestClassifier(\n",
    "#        n_estimators=100,\n",
    "#        max_depth=10,\n",
    "#        min_samples_split=2,\n",
    "#        min_samples_leaf=1,\n",
    "#        random_state=20 \n",
    "#    ))\n",
    "#])\n",
    "\n",
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_fs_smote,\n",
    "#    filtered_X,\n",
    "#    filtered_y,\n",
    "#    cv=kf,\n",
    "#    scoring='f1_macro',\n",
    "#    return_train_score=True,\n",
    "#    verbose=2,\n",
    "#    n_jobs=2\n",
    "#)\n",
    "\n",
    "## Results\n",
    "#print(\"Train F1-Macro scores for each fold:\", cv_results['train_score'])\n",
    "#print(\"Validation F1-Macro scores for each fold:\", cv_results['test_score'])\n",
    "#print(\"Mean Train F1-Macro score:\", cv_results['train_score'].mean())\n",
    "#print(\"Mean Validation F1-Macro score:\", cv_results['test_score'].mean())\n",
    "\n",
    "##Outputs\n",
    "##Train F1-Macro scores for each fold: [0.58718413 0.59346249]\n",
    "##Validation F1-Macro scores for each fold: [0.40123979 0.39024775]\n",
    "##Mean Train F1-Macro score: 0.5903233090982709\n",
    "##Mean Validation F1-Macro score: 0.39574377067822775\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.4.3 Fit using the best pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_fs.fit(filtered_X, filtered_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain the final model fitted in the pipeline\n",
    "#final_model = pipeline_fs.named_steps['rf_model']\n",
    "\n",
    "## Get feature importance\n",
    "#feature_importances = final_model.feature_importances_\n",
    "\n",
    "## Get the feature names after preprocessing\n",
    "## Ensure you retrieve all feature names properly\n",
    "#preprocessor = [step[1] for step in preproc_steps if isinstance(step[1], ColumnTransformer)][0]\n",
    "#try:\n",
    "#    feature_names = preprocessor.get_feature_names_out()\n",
    "#except AttributeError:\n",
    "#    # If feature names are not directly available, handle manually\n",
    "#    feature_names = X.columns  # Original columns as fallback\n",
    "\n",
    "## Validate that feature names and importances match\n",
    "#if len(feature_importances) != len(feature_names):\n",
    "#    print(f\"Mismatch in feature names ({len(feature_names)}) and importances ({len(feature_importances)})\")\n",
    "#    feature_names = [f\"Feature_{i}\" for i in range(len(feature_importances))]  # Fallback to generic names\n",
    "\n",
    "## Create a DataFrame to combine feature names and their importances\n",
    "#feature_importance_df = pd.DataFrame({\n",
    "#    'Feature': feature_names,\n",
    "#    'Importance': feature_importances\n",
    "#})\n",
    "\n",
    "## Sort by importance\n",
    "#feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "## Visualize graphically\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))  # Top 20 features\n",
    "#plt.title(\"Feature Importance from RandomForest\")\n",
    "#plt.xlabel(\"Importance\")\n",
    "#plt.ylabel(\"Feature\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply StratifiedKFold on the filtered training set\n",
    "#for train_idx, val_idx in kf.split(filtered_X, filtered_y):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = filtered_X.iloc[train_idx], filtered_X.iloc[val_idx]\n",
    "#    y_train, y_val = filtered_y[train_idx], filtered_y[val_idx]\n",
    "#    \n",
    "#    # Fit the final pipeline on the training fold\n",
    "#    pipeline_fs.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_fs.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the confusion matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "#                xticklabels=pipeline_fs.named_steps['rf_model'].classes_, \n",
    "#                yticklabels=pipeline_fs.named_steps['rf_model'].classes_)\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "#    \n",
    "#    # Stop after the first fold\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"eighteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.7. Naive Bayes\n",
    "</a> \n",
    "</d> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a Naive Bayes model with the main objective of making a stacking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline with GaussianNB\n",
    "#pipeline_NB = Pipeline(steps=[\n",
    "#    *preproc_steps,\n",
    "#    ('model', GaussianNB())\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the first fold\n",
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    pipeline_NB.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = pipeline_NB.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline_NB.classes_, yticklabels=pipeline_NB.classes_)\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "#    \n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.3 F1-Macro, Recall-Macro and Precision-Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    pipeline_NB,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## F1-Macro\n",
    "#train_f1_scores = cv_results['train_f1_macro']\n",
    "#val_f1_scores = cv_results['test_f1_macro']\n",
    "#print(\"Train F1-Macro scores for each fold:\", train_f1_scores)\n",
    "#print(\"Validation F1-Macro scores for each fold:\", val_f1_scores)\n",
    "#print(\"Mean Train F1-Macro score:\", train_f1_scores.mean())\n",
    "#print(\"Mean Validation F1-Macro score:\", val_f1_scores.mean())\n",
    "#print(\"Std Dev Train F1-Macro score:\", train_f1_scores.std())\n",
    "#print(\"Std Dev Validation F1-Macro score:\", val_f1_scores.std())\n",
    "\n",
    "## Recall-Macro\n",
    "#train_recall_scores = cv_results['train_recall_macro']\n",
    "#val_recall_scores = cv_results['test_recall_macro']\n",
    "#print(\"\\nMean Train Recall-Macro score:\", train_recall_scores.mean())\n",
    "#print(\"Mean Validation Recall-Macro score:\", val_recall_scores.mean())\n",
    "#print(\"Std Dev Train Recall-Macro score:\", train_recall_scores.std())\n",
    "#print(\"Std Dev Validation Recall-Macro score:\", val_recall_scores.std())\n",
    "\n",
    "## Precision-Macro\n",
    "#train_precision_scores = cv_results['train_precision_macro']\n",
    "#val_precision_scores = cv_results['test_precision_macro']\n",
    "#print(\"\\nMean Train Precision-Macro score:\", train_precision_scores.mean())\n",
    "#print(\"Mean Validation Precision-Macro score:\", val_precision_scores.mean())\n",
    "#print(\"Std Dev Train Precision-Macro score:\", train_precision_scores.std())\n",
    "#print(\"Std Dev Validation Precision-Macro score:\", val_precision_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nineteen-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 3.8 Stacking: Logistic Regression and Naive Bayes\n",
    "</a> \n",
    "</d> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the estimators\n",
    "#stacking_model_lr_nb = StackingClassifier(\n",
    "#    estimators=[\n",
    "#        ('logistic_regression', pipeline_LR),\n",
    "#        ('naive_bayes', pipeline_NB)\n",
    "#    ],\n",
    "#    final_estimator=LogisticRegression(\n",
    "#            random_state=42,\n",
    "#            max_iter=1000,\n",
    "#            C = 100,\n",
    "#            l1_ratio = 0.2,\n",
    "#            penalty = 'l2',\n",
    "#            solver = 'newton-cg'),\n",
    "#    cv=None\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the first fold\n",
    "#for train_idx, val_idx in kf.split(X, y_encoded):\n",
    "#    # Split the data into training and validation sets\n",
    "#    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "#    \n",
    "#    # Fit the pipeline on the training fold\n",
    "#    stacking_model_lr_nb.fit(X_train, y_train)\n",
    "#    \n",
    "#    # Make predictions on the validation set\n",
    "#    y_val_pred = stacking_model_lr_nb.predict(X_val)\n",
    "#    \n",
    "#    # Compute the confusion matrix\n",
    "#    cm = confusion_matrix(y_val, y_val_pred)\n",
    "#    \n",
    "#    # Display the matrix graphically\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stacking_model_lr_nb.classes_, yticklabels=stacking_model_lr_nb.classes_)\n",
    "#    plt.title(\"Confusion Matrix for a Single Fold\")\n",
    "#    plt.ylabel(\"Actual\")\n",
    "#    plt.xlabel(\"Predicted\")\n",
    "#    plt.show()\n",
    "#    \n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.3 F1-Macro, Recall-Macro and Precision-Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "#cv_results = cross_validate(\n",
    "#    stacking_model_lr_nb,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#)\n",
    "\n",
    "## F1-Macro\n",
    "#train_f1_scores = cv_results['train_f1_macro']\n",
    "#val_f1_scores = cv_results['test_f1_macro']\n",
    "#print(\"Train F1-Macro scores for each fold:\", train_f1_scores)\n",
    "#print(\"Validation F1-Macro scores for each fold:\", val_f1_scores)\n",
    "#print(\"Mean Train F1-Macro score:\", train_f1_scores.mean())\n",
    "#print(\"Mean Validation F1-Macro score:\", val_f1_scores.mean())\n",
    "#print(\"Std Dev Train F1-Macro score:\", train_f1_scores.std())\n",
    "#print(\"Std Dev Validation F1-Macro score:\", val_f1_scores.std())\n",
    "\n",
    "## Recall-Macro\n",
    "#train_recall_scores = cv_results['train_recall_macro']\n",
    "#val_recall_scores = cv_results['test_recall_macro']\n",
    "#print(\"\\nMean Train Recall-Macro score:\", train_recall_scores.mean())\n",
    "#print(\"Mean Validation Recall-Macro score:\", val_recall_scores.mean())\n",
    "#print(\"Std Dev Train Recall-Macro score:\", train_recall_scores.std())\n",
    "#print(\"Std Dev Validation Recall-Macro score:\", val_recall_scores.std())\n",
    "\n",
    "## Precision-Macro\n",
    "#train_precision_scores = cv_results['train_precision_macro']\n",
    "#val_precision_scores = cv_results['test_precision_macro']\n",
    "#print(\"\\nMean Train Precision-Macro score:\", train_precision_scores.mean())\n",
    "#print(\"Mean Validation Precision-Macro score:\", val_precision_scores.mean())\n",
    "#print(\"Std Dev Train Precision-Macro score:\", train_precision_scores.std())\n",
    "#print(\"Std Dev Validation Precision-Macro score:\", val_precision_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twenty-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "## 4. Model Evaluation\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twentyone-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 4.1. Accuracy Macro, Precision Macro, Recall Macro, F1 Macro\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_metrics(model, sample = 'train'):\n",
    "#    # Scoring Metrics\n",
    "#    scoring = {\n",
    "#    'accuracy_macro': make_scorer(accuracy_score, average='macro'),  \n",
    "#    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "#    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "#    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "#    }\n",
    "\n",
    "#    # Cross Validation\n",
    "#    cv_results = cross_validate(\n",
    "#    model,\n",
    "#    X,\n",
    "#    y_encoded,\n",
    "#    cv=kf,\n",
    "#    scoring=scoring,\n",
    "#    return_train_score=True\n",
    "#    )\n",
    "\n",
    "#    # Accuracy-Macro\n",
    "#    train_accuracy_scores = cv_results['train_accuracy_macro']\n",
    "#    val_accuracy_scores = cv_results['test_accuracy_macro']\n",
    "\n",
    "#    # Precision-Macro\n",
    "#    train_precision_scores = cv_results['train_precision_macro']\n",
    "#    val_precision_scores = cv_results['test_precision_macro']\n",
    "\n",
    "#    # Recall-Macro\n",
    "#    train_recall_scores = cv_results['train_recall_macro']\n",
    "#    val_recall_scores = cv_results['test_recall_macro']\n",
    "\n",
    "#    # F1-Macro\n",
    "#    train_f1_scores = cv_results['train_f1_macro']\n",
    "#    val_f1_scores = cv_results['test_f1_macro']\n",
    "\n",
    "#    if sample == 'train':\n",
    "#        result = [train_accuracy_scores.mean(), train_precision_scores.mean(), train_recall_scores.mean(), train_f1_scores.mean()]\n",
    "#    elif sample == 'val':\n",
    "#        result = [val_accuracy_scores.mean(), val_precision_scores.mean(), val_recall_scores.mean(), val_f1_scores.mean()]\n",
    "    \n",
    "\n",
    "#    return result\n",
    "\n",
    "## Metris used\n",
    "#metric_names =['Accuracy Macro', 'Precision Macro', 'Recall Macro', 'F1 Macro']\n",
    "\n",
    "## Final Results for Train for each model\n",
    "#final_results_train = pd.DataFrame({\n",
    "#  'XGBoost': get_metrics(pipeline_XGB),\n",
    "#  'Neural Networks': get_metrics(pipeline_NN),\n",
    "#  'Decision Tree':  get_metrics(pipeline_DT),\n",
    "#  'Bagging':  get_metrics(pipeline_DT_Best),\n",
    "#  'Logistic Regression': get_metrics(pipeline_LR_KB_FULL), \n",
    "#  'Random Forest': get_metrics(pipeline_fs)\n",
    "#  }, index=metric_names)   \n",
    "\n",
    "## Final Results for Val for each model\n",
    "#final_results_val = pd.DataFrame({\n",
    "#  'XGBoost': get_metrics(pipeline_XGB, 'val'),\n",
    "#  'Neural Networks': get_metrics(pipeline_NN, 'val'),\n",
    "#  'Decision Tree':  get_metrics(pipeline_DT, 'val'),\n",
    "#  'Bagging':  get_metrics(pipeline_DT_Best, 'val'),\n",
    "#  'Logistic Regression': get_metrics(pipeline_LR_KB_FULL, 'val'), \n",
    "#  'Random Forest': get_metrics(pipeline_fs, 'val')\n",
    "#  }, index=metric_names)     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Model Evaluation X_train: \")\n",
    "#print(final_results_train)\n",
    "#print(\"-------------------------------------------------------\")\n",
    "#print(\"Model Evaluation X_val: \")\n",
    "#print(final_results_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twentytwo-bullet\"> \n",
    "<d style=\"color:white;\">\n",
    "\n",
    "### 4.2. Prediction Submission\n",
    "</a> \n",
    "</d>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = pipeline_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;clip_outliers&#x27;,\n",
       "                 ClipOutliersMulti(fixed_limits={&#x27;IME-4 Count&#x27;: (None, 40)},\n",
       "                                   quantile_limits={&#x27;Age at Injury&#x27;: (0.01,\n",
       "                                                                      0.95),\n",
       "                                                    &#x27;Average Weekly Wage&#x27;: (None,\n",
       "                                                                            0.75),\n",
       "                                                    &#x27;Birth Year&#x27;: (0.01, 0.95),\n",
       "                                                    &#x27;Days Difference&#x27;: (None,\n",
       "                                                                        0.8)})),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;scaler&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;Age at Injury&#x27;,\n",
       "                                                   &#x27;Average Weekly Wage&#x27;...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=200, n_jobs=None,\n",
       "                               num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;clip_outliers&#x27;,\n",
       "                 ClipOutliersMulti(fixed_limits={&#x27;IME-4 Count&#x27;: (None, 40)},\n",
       "                                   quantile_limits={&#x27;Age at Injury&#x27;: (0.01,\n",
       "                                                                      0.95),\n",
       "                                                    &#x27;Average Weekly Wage&#x27;: (None,\n",
       "                                                                            0.75),\n",
       "                                                    &#x27;Birth Year&#x27;: (0.01, 0.95),\n",
       "                                                    &#x27;Days Difference&#x27;: (None,\n",
       "                                                                        0.8)})),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;scaler&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;Age at Injury&#x27;,\n",
       "                                                   &#x27;Average Weekly Wage&#x27;...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=200, n_jobs=None,\n",
       "                               num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">ClipOutliersMulti</label><div class=\"sk-toggleable__content fitted\"><pre>ClipOutliersMulti(fixed_limits={&#x27;IME-4 Count&#x27;: (None, 40)},\n",
       "                  quantile_limits={&#x27;Age at Injury&#x27;: (0.01, 0.95),\n",
       "                                   &#x27;Average Weekly Wage&#x27;: (None, 0.75),\n",
       "                                   &#x27;Birth Year&#x27;: (0.01, 0.95),\n",
       "                                   &#x27;Days Difference&#x27;: (None, 0.8)})</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;scaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;Age at Injury&#x27;, &#x27;Average Weekly Wage&#x27;,\n",
       "                                  &#x27;Birth Year&#x27;, &#x27;IME-4 Count&#x27;,\n",
       "                                  &#x27;Number of Dependents&#x27;, &#x27;Days Difference&#x27;,\n",
       "                                  &#x27;Accident Date_year&#x27;, &#x27;Accident Date_month&#x27;,\n",
       "                                  &#x27;Accident Date_day&#x27;, &#x27;Assembly Date_year&#x27;,\n",
       "                                  &#x27;Assembly Date_month&#x27;, &#x27;Assembly Date_day&#x27;,\n",
       "                                  &#x27;C-2 Date_year&#x27;, &#x27;C-2 Date_month&#x27;,\n",
       "                                  &#x27;C-2 Date_day&#x27;, &#x27;C-3 Date_year&#x27;,\n",
       "                                  &#x27;C-3 Date_month&#x27;, &#x27;C-3 Date_day&#x27;,\n",
       "                                  &#x27;First Hearing Date_year&#x27;,\n",
       "                                  &#x27;First Hearing Date_month&#x27;,\n",
       "                                  &#x27;First Hearing Date_day&#x27;]),\n",
       "                                (&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Carrier Type&#x27;, &#x27;District Name&#x27;,\n",
       "                                  &#x27;Medical Fee Region&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">scaler</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Age at Injury&#x27;, &#x27;Average Weekly Wage&#x27;, &#x27;Birth Year&#x27;, &#x27;IME-4 Count&#x27;, &#x27;Number of Dependents&#x27;, &#x27;Days Difference&#x27;, &#x27;Accident Date_year&#x27;, &#x27;Accident Date_month&#x27;, &#x27;Accident Date_day&#x27;, &#x27;Assembly Date_year&#x27;, &#x27;Assembly Date_month&#x27;, &#x27;Assembly Date_day&#x27;, &#x27;C-2 Date_year&#x27;, &#x27;C-2 Date_month&#x27;, &#x27;C-2 Date_day&#x27;, &#x27;C-3 Date_year&#x27;, &#x27;C-3 Date_month&#x27;, &#x27;C-3 Date_day&#x27;, &#x27;First Hearing Date_year&#x27;, &#x27;First Hearing Date_month&#x27;, &#x27;First Hearing Date_day&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehot</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Carrier Type&#x27;, &#x27;District Name&#x27;, &#x27;Medical Fee Region&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Alternative Dispute Resolution&#x27;, &#x27;Attorney/Representative&#x27;, &#x27;Carrier Name&#x27;, &#x27;County of Injury&#x27;, &#x27;COVID-19 Indicator&#x27;, &#x27;Gender&#x27;, &#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;, &#x27;WCIO Nature of Injury Code&#x27;, &#x27;WCIO Part Of Body Code&#x27;, &#x27;Zip Code&#x27;, &#x27;C-2 Missed Timing&#x27;, &#x27;C-3 Missed Timing&#x27;, &#x27;C-2 Missing&#x27;, &#x27;C-3 Missing&#x27;, &#x27;Has Hearing&#x27;, &#x27;Has IME-4 Report&#x27;, &#x27;Log Age at Injury&#x27;, &#x27;Log Average Weekly Wage&#x27;, &#x27;Log Birth Year&#x27;, &#x27;Log IME-4 Count&#x27;, &#x27;Log Number of Dependents&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FrequencyEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>FrequencyEncoder(columns=[&#x27;Carrier Name&#x27;, &#x27;County of Injury&#x27;, &#x27;Zip Code&#x27;])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SampleKNNImputer</label><div class=\"sk-toggleable__content fitted\"><pre>SampleKNNImputer(features=[&#x27;Alternative Dispute Resolution&#x27;,\n",
       "                           &#x27;Average Weekly Wage&#x27;, &#x27;Age at Injury&#x27;, &#x27;Birth Year&#x27;,\n",
       "                           &#x27;Carrier Name&#x27;, &#x27;Gender&#x27;, &#x27;Zip Code&#x27;,\n",
       "                           &#x27;Accident Date_year&#x27;, &#x27;Accident Date_month&#x27;,\n",
       "                           &#x27;Accident Date_day&#x27;, &#x27;Days Difference&#x27;,\n",
       "                           &#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;,\n",
       "                           &#x27;WCIO Nature of Injury Code&#x27;,\n",
       "                           &#x27;WCIO Part Of Body Code&#x27;, &#x27;C-2 Missed Timing&#x27;,\n",
       "                           &#x27;C-3 Missed Timing&#x27;, &#x27;Log Average Weekly Wage&#x27;,\n",
       "                           &#x27;Log Birth Year&#x27;, &#x27;Log IME-4 Count&#x27;],\n",
       "                 sample_size=1000, weights=&#x27;uniform&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">ConvertDataType</label><div class=\"sk-toggleable__content fitted\"><pre>ConvertDataType(columns=[&#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;,\n",
       "                         &#x27;WCIO Nature of Injury Code&#x27;,\n",
       "                         &#x27;WCIO Part Of Body Code&#x27;],\n",
       "                dtype=&#x27;int&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FixCodes</label><div class=\"sk-toggleable__content fitted\"><pre>FixCodes(columns=[&#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;,\n",
       "                  &#x27;WCIO Nature of Injury Code&#x27;, &#x27;WCIO Part Of Body Code&#x27;],\n",
       "         valid_codes={&#x27;Industry Code&#x27;: {&#x27;Other Services&#x27;: [56, 81],\n",
       "                                        &#x27;Primary Industry&#x27;: [11, 21, 22],\n",
       "                                        &#x27;Quaternary Industry&#x27;: [51, 52, 54, 55],\n",
       "                                        &#x27;Recreational and Hospitality Services&#x27;: [71,\n",
       "                                                                                  72],\n",
       "                                        &#x27;Secondary Industry&#x27;: [23, 31],\n",
       "                                        &#x27;Social and Public Services&#x27;: [61, 62,\n",
       "                                                                       92],\n",
       "                                        &#x27;Tertiary Industry&#x27;:...\n",
       "                                                                                                   76,\n",
       "                                                                                                   77,\n",
       "                                                                                                   78,\n",
       "                                                                                                   79,\n",
       "                                                                                                   80,\n",
       "                                                                                                   83],\n",
       "                                                     &#x27;Specific Injury&#x27;: [1, 2,\n",
       "                                                                         3, 4,\n",
       "                                                                         7, 10,\n",
       "                                                                         13, 16,\n",
       "                                                                         19, 22,\n",
       "                                                                         25, 28,\n",
       "                                                                         30, 31,\n",
       "                                                                         32, 34,\n",
       "                                                                         36, 37,\n",
       "                                                                         38, 40,\n",
       "                                                                         41, 42,\n",
       "                                                                         43, 46,\n",
       "                                                                         47, 49,\n",
       "                                                                         52, 53,\n",
       "                                                                         54, 55, ...]},\n",
       "                      &#x27;WCIO Part Of Body Code&#x27;: {&#x27;Head&#x27;: range(10, 20),\n",
       "                                                 &#x27;Lower Extremities&#x27;: range(50, 59),\n",
       "                                                 &#x27;Multiple Body Parts&#x27;: [9, 64,\n",
       "                                                                         65, 66,\n",
       "                                                                         90, 91,\n",
       "                                                                         99],\n",
       "                                                 &#x27;Neck&#x27;: range(20, 27),\n",
       "                                                 &#x27;Trunk&#x27;: [40, 41, 42, 43, 44,\n",
       "                                                           45, 46, 47, 48, 49,\n",
       "                                                           60, 61, 62, 63],\n",
       "                                                 &#x27;Upper Extremities&#x27;: range(30, 40)}})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">ZeroFillImputer</label><div class=\"sk-toggleable__content fitted\"><pre>ZeroFillImputer(features=[&#x27;IME-4 Count&#x27;, &#x27;C-2 Date_year&#x27;, &#x27;C-2 Date_month&#x27;,\n",
       "                          &#x27;C-2 Date_day&#x27;, &#x27;C-3 Date_year&#x27;, &#x27;C-3 Date_month&#x27;,\n",
       "                          &#x27;C-3 Date_day&#x27;, &#x27;First Hearing Date_year&#x27;,\n",
       "                          &#x27;First Hearing Date_month&#x27;,\n",
       "                          &#x27;First Hearing Date_day&#x27;])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CodeMapper</label><div class=\"sk-toggleable__content fitted\"><pre>CodeMapper(mapping_dict={&#x27;Industry Code&#x27;: {&#x27;Other Services&#x27;: [56, 81],\n",
       "                                           &#x27;Primary Industry&#x27;: [11, 21, 22],\n",
       "                                           &#x27;Quaternary Industry&#x27;: [51, 52, 54,\n",
       "                                                                   55],\n",
       "                                           &#x27;Recreational and Hospitality Services&#x27;: [71,\n",
       "                                                                                     72],\n",
       "                                           &#x27;Secondary Industry&#x27;: [23, 31],\n",
       "                                           &#x27;Social and Public Services&#x27;: [61,\n",
       "                                                                          62,\n",
       "                                                                          92],\n",
       "                                           &#x27;Tertiary Industry&#x27;: [42, 44, 48,\n",
       "                                                                 53]},\n",
       "                         &#x27;WCIO Cause of Injury Code&#x27;: {&#x27;Burn or Scald - Heat or Cold Exposures - Contact With&#x27;: [1,\n",
       "                                                                                                                 2,\n",
       "                                                                                                                 3...\n",
       "                                                                                                      76,\n",
       "                                                                                                      77,\n",
       "                                                                                                      78,\n",
       "                                                                                                      79,\n",
       "                                                                                                      80,\n",
       "                                                                                                      83],\n",
       "                                                        &#x27;Specific Injury&#x27;: [1,\n",
       "                                                                            2,\n",
       "                                                                            3,\n",
       "                                                                            4,\n",
       "                                                                            7,\n",
       "                                                                            10,\n",
       "                                                                            13,\n",
       "                                                                            16,\n",
       "                                                                            19,\n",
       "                                                                            22,\n",
       "                                                                            25,\n",
       "                                                                            28,\n",
       "                                                                            30,\n",
       "                                                                            31,\n",
       "                                                                            32,\n",
       "                                                                            34,\n",
       "                                                                            36,\n",
       "                                                                            37,\n",
       "                                                                            38,\n",
       "                                                                            40,\n",
       "                                                                            41,\n",
       "                                                                            42,\n",
       "                                                                            43,\n",
       "                                                                            46,\n",
       "                                                                            47,\n",
       "                                                                            49,\n",
       "                                                                            52,\n",
       "                                                                            53,\n",
       "                                                                            54,\n",
       "                                                                            55, ...]},\n",
       "                         &#x27;WCIO Part Of Body Code&#x27;: {&#x27;Head&#x27;: range(10, 20),\n",
       "                                                    &#x27;Lower Extremities&#x27;: range(50, 59),\n",
       "                                                    &#x27;Multiple Body Parts&#x27;: [9,\n",
       "                                                                            64,\n",
       "                                                                            65,\n",
       "                                                                            66,\n",
       "                                                                            90,\n",
       "                                                                            91,\n",
       "                                                                            99],\n",
       "                                                    &#x27;Neck&#x27;: range(20, 27),\n",
       "                                                    &#x27;Trunk&#x27;: [40, 41, 42, 43,\n",
       "                                                              44, 45, 46, 47,\n",
       "                                                              48, 49, 60, 61,\n",
       "                                                              62, 63],\n",
       "                                                    &#x27;Upper Extremities&#x27;: range(30, 40)}})</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;oh_codes: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for oh_codes: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;,\n",
       "                                  &#x27;WCIO Nature of Injury Code&#x27;,\n",
       "                                  &#x27;WCIO Part Of Body Code&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehot</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Industry Code&#x27;, &#x27;WCIO Cause of Injury Code&#x27;, &#x27;WCIO Nature of Injury Code&#x27;, &#x27;WCIO Part Of Body Code&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Age at Injury&#x27;, &#x27;Average Weekly Wage&#x27;, &#x27;Birth Year&#x27;, &#x27;IME-4 Count&#x27;, &#x27;Number of Dependents&#x27;, &#x27;Days Difference&#x27;, &#x27;Accident Date_year&#x27;, &#x27;Accident Date_month&#x27;, &#x27;Accident Date_day&#x27;, &#x27;Assembly Date_year&#x27;, &#x27;Assembly Date_month&#x27;, &#x27;Assembly Date_day&#x27;, &#x27;C-2 Date_year&#x27;, &#x27;C-2 Date_month&#x27;, &#x27;C-2 Date_day&#x27;, &#x27;C-3 Date_year&#x27;, &#x27;C-3 Date_month&#x27;, &#x27;C-3 Date_day&#x27;, &#x27;First Hearing Date_year&#x27;, &#x27;First Hearing Date_month&#x27;, &#x27;First Hearing Date_day&#x27;, &#x27;Carrier Type_2A. SIF&#x27;, &#x27;Carrier Type_3A. SELF PUBLIC&#x27;, &#x27;Carrier Type_4A. SELF PRIVATE&#x27;, &#x27;Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)&#x27;, &#x27;Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS&#x27;, &#x27;Carrier Type_5D. SPECIAL FUND - UNKNOWN&#x27;, &#x27;Carrier Type_UNKNOWN&#x27;, &#x27;District Name_BINGHAMTON&#x27;, &#x27;District Name_BUFFALO&#x27;, &#x27;District Name_HAUPPAUGE&#x27;, &#x27;District Name_NYC&#x27;, &#x27;District Name_ROCHESTER&#x27;, &#x27;District Name_STATEWIDE&#x27;, &#x27;District Name_SYRACUSE&#x27;, &#x27;Medical Fee Region_II&#x27;, &#x27;Medical Fee Region_III&#x27;, &#x27;Medical Fee Region_IV&#x27;, &#x27;Medical Fee Region_UK&#x27;, &#x27;Alternative Dispute Resolution&#x27;, &#x27;Attorney/Representative&#x27;, &#x27;Carrier Name&#x27;, &#x27;County of Injury&#x27;, &#x27;COVID-19 Indicator&#x27;, &#x27;Gender&#x27;, &#x27;Zip Code&#x27;, &#x27;C-2 Missed Timing&#x27;, &#x27;C-3 Missed Timing&#x27;, &#x27;C-2 Missing&#x27;, &#x27;C-3 Missing&#x27;, &#x27;Has Hearing&#x27;, &#x27;Has IME-4 Report&#x27;, &#x27;Log Age at Injury&#x27;, &#x27;Log Average Weekly Wage&#x27;, &#x27;Log Birth Year&#x27;, &#x27;Log IME-4 Count&#x27;, &#x27;Log Number of Dependents&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">feature_selector: XGBFeatureSelector</label><div class=\"sk-toggleable__content fitted\"><pre>XGBFeatureSelector(model=XGBClassifier(base_score=None, booster=None,\n",
       "                                       callbacks=None, colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None, device=None,\n",
       "                                       early_stopping_rounds=None,\n",
       "                                       enable_categorical=False,\n",
       "                                       eval_metric=&#x27;mlogloss&#x27;,\n",
       "                                       feature_types=None, gamma=None,\n",
       "                                       grow_policy=None, importance_type=None,\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=0.1, max_bin=None,\n",
       "                                       max_cat_threshold=None,\n",
       "                                       max_cat_to_onehot=None,\n",
       "                                       max_delta_step=None, max_depth=6,\n",
       "                                       max_leaves=None, min_child_weight=None,\n",
       "                                       missing=nan, monotone_constraints=None,\n",
       "                                       multi_strategy=None, n_estimators=200,\n",
       "                                       n_jobs=None, num_parallel_tree=None,\n",
       "                                       objective=&#x27;multi:softprob&#x27;, ...),\n",
       "                   num_features=53)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">model: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('clip_outliers',\n",
       "                 ClipOutliersMulti(fixed_limits={'IME-4 Count': (None, 40)},\n",
       "                                   quantile_limits={'Age at Injury': (0.01,\n",
       "                                                                      0.95),\n",
       "                                                    'Average Weekly Wage': (None,\n",
       "                                                                            0.75),\n",
       "                                                    'Birth Year': (0.01, 0.95),\n",
       "                                                    'Days Difference': (None,\n",
       "                                                                        0.8)})),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('scaler', MinMaxScaler(),\n",
       "                                                  ['Age at Injury',\n",
       "                                                   'Average Weekly Wage'...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=200, n_jobs=None,\n",
       "                               num_parallel_tree=None,\n",
       "                               objective='multi:softprob', ...))])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.fit(X,y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_encoded = best_pipeline.predict(df_test)  # Encoded predictions\n",
    "\n",
    "# Map the classes to the expected labels for submission\n",
    "class_mapping = {\n",
    "    0: \"1. CANCELLED\",\n",
    "    1: \"2. NON-COMP\",\n",
    "    2: \"3. MED ONLY\",\n",
    "    3: \"4. TEMPORARY\",\n",
    "    4: \"5. PPD SCH LOSS\",\n",
    "    5: \"6. PPD NSL\",\n",
    "    6: \"7. PTD\",\n",
    "    7: \"8. DEATH\"\n",
    "}\n",
    "\n",
    "# Create the submission DataFrame\n",
    "df_submission = pd.DataFrame({\n",
    "    'Claim Identifier': df_test.index,  # Ensure that the index of df_test is the correct identifier\n",
    "    'Claim Injury Type': y_test_pred_encoded\n",
    "})\n",
    "\n",
    "# Map class codes to original labels\n",
    "df_submission['Claim Injury Type'] = df_submission['Claim Injury Type'].map(class_mapping)\n",
    "\n",
    "# Save the submission file\n",
    "df_submission.to_csv(\"Group43_Version18.csv\", index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
